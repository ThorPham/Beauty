{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense,Flatten,BatchNormalization,Convolution2D,MaxPooling2D,Activation\n",
    "#from keras.applications.\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.layers import Dropout\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "import cv2\n",
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import numpy\n",
    "from os import path\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import scipy.misc\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "def detectFace(detector,image_path, image_name):\n",
    "    imgAbsPath = os.path.join(image_path,image_name)\n",
    "    img = cv2.imread(imgAbsPath)\n",
    "    faces = detector.detect_faces(img)\n",
    "    croped_im = np.ones(1)\n",
    "    if len(faces) == 1:\n",
    "        bbox = faces[0][\"box\"]\n",
    "        x,y,w,h = bbox\n",
    "        (xmin,ymin),(xmax,ymax) = (x,y),(x+w,y+h)\n",
    "        croped_im = img[y:y+h,x:x+w,:]\n",
    "        #print(croped_im.shape)\n",
    "        try :\n",
    "            resized_im = cv2.resize(croped_im, (240,180))\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "#         if resized_im.shape[0] != 224 or resized_im.shape[1] != 224:\n",
    "#             print(\"invalid shape\")\n",
    "\n",
    "        # cv2.imwrite(image_name, resized_im)\n",
    "#     else:\n",
    "#         print(image_name+\" error \" + str(len(faces)))\n",
    "    return croped_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "label_file = \"/home/minhhv/dung/face/SCUT-FBP5500_v2/train_test_files/All_labels.txt\"\n",
    "label = pd.read_csv(label_file,sep=\" \",header=None)\n",
    "label.columns = [\"name_image\",\"score\"]\n",
    "name_images = label[\"name_image\"]\n",
    "scores = label[\"score\"]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 163, 3)\n",
      "(296, 218, 3)\n",
      "(206, 157, 3)\n",
      "(234, 179, 3)\n",
      "(223, 176, 3)\n",
      "(265, 200, 3)\n",
      "(262, 190, 3)\n",
      "(282, 211, 3)\n",
      "(290, 228, 3)\n",
      "(210, 155, 3)\n",
      "(215, 168, 3)\n",
      "(257, 189, 3)\n",
      "(246, 185, 3)\n",
      "(229, 175, 3)\n",
      "(267, 208, 3)\n",
      "(226, 178, 3)\n",
      "(220, 179, 3)\n",
      "(222, 173, 3)\n",
      "(235, 185, 3)\n",
      "(201, 162, 3)\n",
      "(257, 186, 3)\n",
      "(229, 177, 3)\n",
      "(216, 178, 3)\n",
      "(226, 181, 3)\n",
      "(261, 191, 3)\n",
      "(250, 189, 3)\n",
      "(241, 184, 3)\n",
      "(211, 169, 3)\n",
      "(250, 190, 3)\n",
      "(230, 175, 3)\n",
      "(217, 155, 3)\n",
      "(209, 168, 3)\n",
      "(233, 177, 3)\n",
      "(202, 163, 3)\n",
      "(206, 154, 3)\n",
      "(211, 160, 3)\n",
      "(216, 167, 3)\n",
      "(228, 181, 3)\n",
      "(285, 230, 3)\n",
      "(275, 202, 3)\n",
      "(227, 188, 3)\n",
      "(219, 167, 3)\n",
      "(276, 213, 3)\n",
      "(226, 177, 3)\n",
      "(221, 159, 3)\n",
      "(260, 189, 3)\n",
      "(200, 153, 3)\n",
      "(219, 165, 3)\n",
      "(204, 159, 3)\n",
      "(230, 171, 3)\n",
      "(186, 145, 3)\n",
      "(227, 175, 3)\n",
      "(220, 149, 3)\n",
      "(227, 180, 3)\n",
      "(247, 183, 3)\n",
      "(233, 177, 3)\n",
      "(246, 183, 3)\n",
      "(200, 160, 3)\n",
      "(220, 165, 3)\n",
      "(211, 163, 3)\n",
      "(310, 241, 3)\n",
      "(245, 178, 3)\n",
      "(284, 215, 3)\n",
      "(194, 156, 3)\n",
      "(214, 169, 3)\n",
      "(261, 191, 3)\n",
      "(248, 191, 3)\n",
      "(241, 200, 3)\n",
      "(229, 172, 3)\n",
      "(214, 163, 3)\n",
      "(306, 230, 3)\n",
      "(238, 189, 3)\n",
      "(302, 223, 3)\n",
      "(208, 161, 3)\n",
      "(248, 190, 3)\n",
      "(254, 179, 3)\n",
      "(242, 190, 3)\n",
      "(248, 177, 3)\n",
      "(285, 208, 3)\n",
      "(332, 245, 3)\n",
      "(238, 183, 3)\n",
      "(223, 161, 3)\n",
      "(198, 154, 3)\n",
      "(287, 235, 3)\n",
      "(249, 195, 3)\n",
      "(235, 183, 3)\n",
      "(194, 163, 3)\n",
      "(226, 173, 3)\n",
      "(276, 204, 3)\n",
      "(224, 170, 3)\n",
      "(316, 255, 3)\n",
      "(224, 177, 3)\n",
      "(201, 155, 3)\n",
      "(203, 158, 3)\n",
      "(265, 200, 3)\n",
      "(224, 174, 3)\n",
      "(241, 177, 3)\n",
      "(262, 195, 3)\n",
      "(268, 195, 3)\n",
      "(213, 166, 3)\n",
      "(237, 191, 3)\n",
      "(212, 156, 3)\n",
      "(238, 195, 3)\n",
      "(300, 230, 3)\n",
      "(206, 154, 3)\n",
      "(238, 181, 3)\n",
      "(202, 147, 3)\n",
      "(220, 168, 3)\n",
      "(305, 211, 3)\n",
      "(245, 193, 3)\n",
      "(221, 161, 3)\n",
      "(275, 212, 3)\n",
      "(216, 177, 3)\n",
      "(227, 179, 3)\n",
      "(216, 156, 3)\n",
      "(217, 174, 3)\n",
      "(235, 189, 3)\n",
      "(234, 182, 3)\n",
      "(225, 170, 3)\n",
      "(288, 228, 3)\n",
      "(254, 198, 3)\n",
      "(272, 207, 3)\n",
      "(239, 175, 3)\n",
      "(298, 228, 3)\n",
      "(245, 187, 3)\n",
      "(223, 170, 3)\n",
      "(218, 175, 3)\n",
      "(293, 218, 3)\n",
      "(231, 173, 3)\n",
      "(229, 191, 3)\n",
      "(293, 218, 3)\n",
      "(292, 214, 3)\n",
      "(281, 218, 3)\n",
      "(201, 153, 3)\n",
      "(217, 169, 3)\n",
      "(237, 188, 3)\n",
      "(200, 157, 3)\n",
      "(225, 170, 3)\n",
      "(249, 194, 3)\n",
      "(270, 207, 3)\n",
      "(237, 179, 3)\n",
      "(205, 163, 3)\n",
      "(236, 180, 3)\n",
      "(256, 189, 3)\n",
      "(208, 153, 3)\n",
      "(254, 197, 3)\n",
      "(203, 162, 3)\n",
      "(223, 162, 3)\n",
      "(218, 171, 3)\n",
      "(242, 174, 3)\n",
      "(272, 195, 3)\n",
      "(285, 220, 3)\n",
      "(219, 167, 3)\n",
      "(226, 166, 3)\n",
      "(326, 252, 3)\n",
      "(233, 180, 3)\n",
      "(305, 228, 3)\n",
      "(201, 165, 3)\n",
      "(239, 181, 3)\n",
      "(262, 194, 3)\n",
      "(207, 163, 3)\n",
      "(208, 161, 3)\n",
      "(249, 192, 3)\n",
      "(237, 191, 3)\n",
      "(260, 212, 3)\n",
      "(275, 218, 3)\n",
      "(244, 187, 3)\n",
      "(275, 223, 3)\n",
      "(236, 178, 3)\n",
      "(218, 167, 3)\n",
      "(279, 207, 3)\n",
      "(264, 197, 3)\n",
      "(220, 167, 3)\n",
      "(267, 202, 3)\n",
      "(213, 167, 3)\n",
      "(245, 189, 3)\n",
      "(275, 210, 3)\n",
      "(252, 190, 3)\n",
      "(303, 236, 3)\n",
      "(188, 147, 3)\n",
      "(202, 159, 3)\n",
      "(228, 171, 3)\n",
      "(237, 192, 3)\n",
      "(293, 218, 3)\n",
      "(241, 184, 3)\n",
      "(231, 173, 3)\n",
      "(230, 169, 3)\n",
      "(210, 169, 3)\n",
      "(285, 215, 3)\n",
      "(219, 164, 3)\n",
      "(243, 176, 3)\n",
      "(260, 201, 3)\n",
      "(205, 153, 3)\n",
      "(217, 162, 3)\n",
      "(222, 169, 3)\n",
      "(233, 182, 3)\n",
      "(207, 158, 3)\n",
      "(215, 168, 3)\n",
      "(266, 199, 3)\n",
      "(288, 207, 3)\n",
      "(298, 230, 3)\n",
      "(233, 176, 3)\n",
      "(227, 177, 3)\n",
      "(248, 196, 3)\n",
      "(240, 187, 3)\n",
      "(221, 176, 3)\n",
      "(230, 178, 3)\n",
      "(235, 174, 3)\n",
      "(229, 182, 3)\n",
      "(255, 209, 3)\n",
      "(233, 182, 3)\n",
      "(222, 172, 3)\n",
      "(247, 189, 3)\n",
      "(220, 172, 3)\n",
      "(206, 160, 3)\n",
      "(242, 185, 3)\n",
      "(259, 212, 3)\n",
      "(299, 233, 3)\n",
      "(302, 227, 3)\n",
      "(211, 165, 3)\n",
      "(221, 176, 3)\n",
      "(218, 163, 3)\n",
      "(261, 197, 3)\n",
      "(262, 206, 3)\n",
      "(205, 169, 3)\n",
      "(249, 195, 3)\n",
      "(197, 159, 3)\n",
      "(241, 179, 3)\n",
      "(225, 170, 3)\n",
      "(228, 179, 3)\n",
      "(266, 198, 3)\n",
      "(272, 199, 3)\n",
      "(221, 179, 3)\n",
      "(196, 152, 3)\n",
      "(236, 187, 3)\n",
      "(237, 183, 3)\n",
      "(217, 169, 3)\n",
      "(235, 201, 3)\n",
      "(232, 184, 3)\n",
      "(237, 171, 3)\n",
      "(283, 216, 3)\n",
      "(207, 175, 3)\n",
      "(262, 212, 3)\n",
      "(245, 196, 3)\n",
      "(243, 191, 3)\n",
      "(277, 211, 3)\n",
      "(277, 198, 3)\n",
      "(286, 222, 3)\n",
      "(258, 193, 3)\n",
      "(203, 160, 3)\n",
      "(303, 231, 3)\n",
      "(251, 199, 3)\n",
      "(238, 172, 3)\n",
      "(212, 160, 3)\n",
      "(252, 184, 3)\n",
      "(246, 180, 3)\n",
      "(233, 179, 3)\n",
      "(274, 216, 3)\n",
      "(232, 173, 3)\n",
      "(214, 168, 3)\n",
      "(199, 157, 3)\n",
      "(237, 182, 3)\n",
      "(249, 191, 3)\n",
      "(228, 172, 3)\n",
      "(211, 166, 3)\n",
      "(220, 180, 3)\n",
      "(244, 181, 3)\n",
      "(222, 175, 3)\n",
      "(212, 161, 3)\n",
      "(218, 170, 3)\n",
      "(295, 227, 3)\n",
      "(293, 221, 3)\n",
      "(259, 192, 3)\n",
      "(310, 217, 3)\n",
      "(209, 158, 3)\n",
      "(246, 199, 3)\n",
      "(220, 165, 3)\n",
      "(245, 180, 3)\n",
      "(203, 161, 3)\n",
      "(231, 181, 3)\n",
      "(249, 185, 3)\n",
      "(244, 199, 3)\n",
      "(202, 164, 3)\n",
      "(205, 163, 3)\n",
      "(217, 162, 3)\n",
      "(224, 170, 3)\n",
      "(223, 175, 3)\n",
      "(230, 177, 3)\n",
      "(197, 151, 3)\n",
      "(229, 182, 3)\n",
      "(237, 183, 3)\n",
      "(223, 174, 3)\n",
      "(272, 198, 3)\n",
      "(249, 188, 3)\n",
      "(201, 149, 3)\n",
      "(201, 159, 3)\n",
      "(212, 158, 3)\n",
      "(214, 168, 3)\n",
      "(296, 240, 3)\n",
      "(200, 152, 3)\n",
      "(233, 183, 3)\n",
      "(281, 207, 3)\n",
      "(212, 154, 3)\n",
      "(242, 176, 3)\n",
      "(198, 149, 3)\n",
      "(233, 199, 3)\n",
      "(226, 188, 3)\n",
      "(208, 170, 3)\n",
      "(304, 234, 3)\n",
      "(251, 195, 3)\n",
      "(219, 173, 3)\n",
      "(246, 187, 3)\n",
      "(239, 177, 3)\n",
      "(242, 174, 3)\n",
      "(269, 199, 3)\n",
      "(214, 159, 3)\n",
      "(241, 177, 3)\n",
      "(228, 177, 3)\n",
      "(223, 173, 3)\n",
      "(209, 161, 3)\n",
      "(230, 180, 3)\n",
      "(255, 189, 3)\n",
      "(257, 203, 3)\n",
      "(215, 168, 3)\n",
      "(306, 220, 3)\n",
      "(292, 233, 3)\n",
      "(199, 164, 3)\n",
      "(213, 164, 3)\n",
      "(189, 154, 3)\n",
      "(239, 180, 3)\n",
      "(241, 186, 3)\n",
      "(212, 170, 3)\n",
      "(226, 177, 3)\n",
      "(283, 206, 3)\n",
      "(230, 172, 3)\n",
      "(228, 177, 3)\n",
      "(244, 190, 3)\n",
      "(248, 187, 3)\n",
      "(297, 227, 3)\n",
      "(257, 191, 3)\n",
      "(209, 167, 3)\n",
      "(206, 166, 3)\n",
      "(260, 192, 3)\n",
      "(226, 171, 3)\n",
      "(246, 191, 3)\n",
      "(203, 160, 3)\n",
      "(199, 152, 3)\n",
      "(232, 174, 3)\n",
      "(284, 209, 3)\n",
      "(296, 212, 3)\n",
      "(234, 177, 3)\n",
      "(206, 155, 3)\n",
      "(208, 157, 3)\n",
      "(256, 188, 3)\n",
      "(307, 227, 3)\n",
      "(215, 168, 3)\n",
      "(211, 162, 3)\n",
      "(261, 207, 3)\n",
      "(210, 161, 3)\n",
      "(211, 164, 3)\n",
      "(220, 171, 3)\n",
      "(266, 205, 3)\n",
      "(221, 169, 3)\n",
      "(241, 185, 3)\n",
      "(221, 170, 3)\n",
      "(219, 164, 3)\n",
      "(237, 192, 3)\n",
      "(228, 178, 3)\n",
      "(217, 159, 3)\n",
      "(226, 165, 3)\n",
      "(252, 184, 3)\n",
      "(220, 174, 3)\n",
      "(235, 172, 3)\n",
      "(272, 218, 3)\n",
      "(222, 182, 3)\n",
      "(242, 174, 3)\n",
      "(203, 159, 3)\n",
      "(320, 232, 3)\n",
      "(250, 194, 3)\n",
      "(306, 242, 3)\n",
      "(291, 202, 3)\n",
      "(274, 213, 3)\n",
      "(231, 178, 3)\n",
      "(259, 199, 3)\n",
      "(254, 197, 3)\n",
      "(230, 181, 3)\n",
      "(234, 191, 3)\n",
      "(266, 208, 3)\n",
      "(280, 211, 3)\n",
      "(214, 173, 3)\n",
      "(298, 217, 3)\n",
      "(247, 188, 3)\n",
      "(222, 166, 3)\n",
      "(200, 153, 3)\n",
      "(223, 167, 3)\n",
      "(221, 170, 3)\n",
      "(212, 170, 3)\n",
      "(222, 177, 3)\n",
      "(230, 175, 3)\n",
      "(199, 152, 3)\n",
      "(299, 227, 3)\n",
      "(208, 169, 3)\n",
      "(233, 171, 3)\n",
      "(225, 163, 3)\n",
      "(221, 175, 3)\n",
      "(246, 190, 3)\n",
      "(281, 207, 3)\n",
      "(247, 195, 3)\n",
      "(262, 197, 3)\n",
      "(259, 208, 3)\n",
      "(224, 163, 3)\n",
      "(225, 163, 3)\n",
      "(208, 167, 3)\n",
      "(254, 194, 3)\n",
      "(299, 224, 3)\n",
      "(256, 192, 3)\n",
      "(231, 181, 3)\n",
      "(218, 180, 3)\n",
      "(211, 161, 3)\n",
      "(222, 177, 3)\n",
      "(204, 159, 3)\n",
      "(237, 192, 3)\n",
      "(272, 202, 3)\n",
      "(212, 162, 3)\n",
      "(304, 239, 3)\n",
      "(231, 176, 3)\n",
      "(222, 169, 3)\n",
      "(233, 168, 3)\n",
      "(208, 178, 3)\n",
      "(273, 213, 3)\n",
      "(227, 178, 3)\n",
      "(254, 197, 3)\n",
      "(290, 213, 3)\n",
      "(301, 238, 3)\n",
      "(269, 209, 3)\n",
      "(272, 208, 3)\n",
      "(215, 168, 3)\n",
      "(262, 203, 3)\n",
      "(305, 222, 3)\n",
      "(259, 189, 3)\n",
      "(242, 199, 3)\n",
      "(236, 183, 3)\n",
      "(208, 173, 3)\n",
      "(227, 177, 3)\n",
      "(259, 205, 3)\n",
      "(224, 172, 3)\n",
      "(248, 186, 3)\n",
      "(207, 156, 3)\n",
      "(244, 180, 3)\n",
      "(250, 190, 3)\n",
      "(289, 220, 3)\n",
      "(241, 181, 3)\n",
      "(207, 152, 3)\n",
      "(258, 198, 3)\n",
      "(212, 157, 3)\n",
      "(225, 168, 3)\n",
      "(209, 161, 3)\n",
      "(258, 206, 3)\n",
      "(334, 256, 3)\n",
      "(222, 165, 3)\n",
      "(222, 178, 3)\n",
      "(217, 172, 3)\n",
      "(264, 194, 3)\n",
      "(224, 175, 3)\n",
      "(250, 193, 3)\n",
      "(229, 176, 3)\n",
      "(259, 194, 3)\n",
      "(274, 203, 3)\n",
      "(230, 182, 3)\n",
      "(225, 183, 3)\n",
      "(263, 206, 3)\n",
      "(203, 170, 3)\n",
      "(228, 175, 3)\n",
      "(210, 168, 3)\n",
      "(253, 188, 3)\n",
      "(197, 155, 3)\n",
      "(217, 165, 3)\n",
      "(263, 214, 3)\n",
      "(209, 170, 3)\n",
      "(199, 152, 3)\n",
      "(237, 186, 3)\n",
      "(232, 170, 3)\n",
      "(217, 176, 3)\n",
      "(201, 155, 3)\n",
      "(218, 172, 3)\n",
      "(243, 179, 3)\n",
      "(287, 220, 3)\n",
      "(245, 197, 3)\n",
      "(276, 223, 3)\n",
      "(206, 166, 3)\n",
      "(243, 177, 3)\n",
      "(248, 203, 3)\n",
      "(214, 169, 3)\n",
      "(247, 183, 3)\n",
      "(235, 179, 3)\n",
      "(330, 253, 3)\n",
      "(240, 189, 3)\n",
      "(272, 191, 3)\n",
      "(212, 168, 3)\n",
      "(240, 179, 3)\n",
      "(250, 207, 3)\n",
      "(269, 198, 3)\n",
      "(218, 163, 3)\n",
      "(221, 181, 3)\n",
      "(239, 187, 3)\n",
      "(266, 201, 3)\n",
      "(227, 180, 3)\n",
      "(301, 222, 3)\n",
      "(233, 171, 3)\n",
      "(245, 188, 3)\n",
      "(224, 173, 3)\n",
      "(208, 163, 3)\n",
      "(214, 165, 3)\n",
      "(243, 184, 3)\n",
      "(207, 164, 3)\n",
      "(228, 172, 3)\n",
      "(312, 238, 3)\n",
      "(288, 223, 3)\n",
      "(272, 190, 3)\n",
      "(310, 227, 3)\n",
      "(227, 173, 3)\n",
      "(252, 191, 3)\n",
      "(253, 195, 3)\n",
      "(278, 217, 3)\n",
      "(245, 187, 3)\n",
      "(224, 175, 3)\n",
      "(236, 187, 3)\n",
      "(251, 208, 3)\n",
      "(281, 200, 3)\n",
      "(248, 198, 3)\n",
      "(230, 177, 3)\n",
      "(203, 158, 3)\n",
      "(234, 172, 3)\n",
      "(204, 146, 3)\n",
      "(251, 187, 3)\n",
      "(229, 172, 3)\n",
      "(216, 169, 3)\n",
      "(254, 193, 3)\n",
      "(231, 181, 3)\n",
      "(229, 180, 3)\n",
      "(277, 213, 3)\n",
      "(242, 188, 3)\n",
      "(222, 169, 3)\n",
      "(255, 209, 3)\n",
      "(254, 181, 3)\n",
      "(238, 178, 3)\n",
      "(210, 160, 3)\n",
      "(230, 179, 3)\n",
      "(206, 162, 3)\n",
      "(207, 166, 3)\n",
      "(331, 228, 3)\n",
      "(283, 216, 3)\n",
      "(264, 201, 3)\n",
      "(246, 192, 3)\n",
      "(223, 171, 3)\n",
      "(241, 182, 3)\n",
      "(249, 183, 3)\n",
      "(223, 174, 3)\n",
      "(214, 159, 3)\n",
      "(183, 151, 3)\n",
      "(221, 166, 3)\n",
      "(224, 175, 3)\n",
      "(198, 154, 3)\n",
      "(215, 168, 3)\n",
      "(216, 177, 3)\n",
      "(231, 180, 3)\n",
      "(281, 200, 3)\n",
      "(319, 247, 3)\n",
      "(237, 184, 3)\n",
      "(226, 171, 3)\n",
      "(271, 200, 3)\n",
      "(241, 190, 3)\n",
      "(232, 178, 3)\n",
      "(215, 173, 3)\n",
      "(235, 179, 3)\n",
      "(212, 167, 3)\n",
      "(220, 172, 3)\n",
      "(249, 188, 3)\n",
      "(229, 180, 3)\n",
      "(296, 219, 3)\n",
      "(216, 170, 3)\n",
      "(223, 168, 3)\n",
      "(247, 192, 3)\n",
      "(231, 172, 3)\n",
      "(220, 169, 3)\n",
      "(209, 153, 3)\n",
      "(196, 163, 3)\n",
      "(241, 187, 3)\n",
      "(210, 174, 3)\n",
      "(229, 191, 3)\n",
      "(232, 172, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 178, 3)\n",
      "(242, 175, 3)\n",
      "(245, 179, 3)\n",
      "(238, 183, 3)\n",
      "(259, 188, 3)\n",
      "(218, 164, 3)\n",
      "(300, 214, 3)\n",
      "(236, 186, 3)\n",
      "(193, 154, 3)\n",
      "(228, 169, 3)\n",
      "(243, 199, 3)\n",
      "(242, 187, 3)\n",
      "(227, 181, 3)\n",
      "(199, 163, 3)\n",
      "(237, 174, 3)\n",
      "(236, 178, 3)\n",
      "(208, 152, 3)\n",
      "(256, 208, 3)\n",
      "(228, 183, 3)\n",
      "(218, 176, 3)\n",
      "(288, 227, 3)\n",
      "(283, 208, 3)\n",
      "(189, 152, 3)\n",
      "(206, 167, 3)\n",
      "(283, 210, 3)\n",
      "(235, 187, 3)\n",
      "(239, 191, 3)\n",
      "(221, 157, 3)\n",
      "(210, 159, 3)\n",
      "(328, 241, 3)\n",
      "(288, 206, 3)\n",
      "(224, 174, 3)\n",
      "(246, 191, 3)\n",
      "(229, 176, 3)\n",
      "(241, 179, 3)\n",
      "(215, 163, 3)\n",
      "(208, 159, 3)\n",
      "(187, 148, 3)\n",
      "(250, 193, 3)\n",
      "(214, 168, 3)\n",
      "(252, 186, 3)\n",
      "(237, 192, 3)\n",
      "(225, 173, 3)\n",
      "(226, 172, 3)\n",
      "(260, 199, 3)\n",
      "(267, 198, 3)\n",
      "(217, 170, 3)\n",
      "(214, 172, 3)\n",
      "(204, 155, 3)\n",
      "(221, 170, 3)\n",
      "(241, 184, 3)\n",
      "(227, 175, 3)\n",
      "(190, 141, 3)\n",
      "(217, 167, 3)\n",
      "(286, 223, 3)\n",
      "(225, 172, 3)\n",
      "(265, 191, 3)\n",
      "(209, 162, 3)\n",
      "(265, 190, 3)\n",
      "(302, 215, 3)\n",
      "(273, 205, 3)\n",
      "(203, 166, 3)\n",
      "(201, 158, 3)\n",
      "(220, 171, 3)\n",
      "(203, 160, 3)\n",
      "(215, 173, 3)\n",
      "(281, 206, 3)\n",
      "(228, 167, 3)\n",
      "(242, 178, 3)\n",
      "(279, 211, 3)\n",
      "(210, 173, 3)\n",
      "(208, 163, 3)\n",
      "(217, 167, 3)\n",
      "(204, 165, 3)\n",
      "(245, 186, 3)\n",
      "(266, 194, 3)\n",
      "(239, 177, 3)\n",
      "(238, 190, 3)\n",
      "(292, 223, 3)\n",
      "(265, 198, 3)\n",
      "(226, 165, 3)\n",
      "(252, 191, 3)\n",
      "(241, 187, 3)\n",
      "(203, 160, 3)\n",
      "(224, 176, 3)\n",
      "(229, 169, 3)\n",
      "(232, 176, 3)\n",
      "(258, 209, 3)\n",
      "(258, 199, 3)\n",
      "(241, 174, 3)\n",
      "(261, 188, 3)\n",
      "(237, 185, 3)\n",
      "(208, 167, 3)\n",
      "(282, 208, 3)\n",
      "(298, 218, 3)\n",
      "(231, 170, 3)\n",
      "(216, 162, 3)\n",
      "(209, 169, 3)\n",
      "(232, 190, 3)\n",
      "(203, 164, 3)\n",
      "(214, 163, 3)\n",
      "(262, 191, 3)\n",
      "(248, 191, 3)\n",
      "(215, 170, 3)\n",
      "(236, 178, 3)\n",
      "(260, 199, 3)\n",
      "(245, 176, 3)\n",
      "(222, 173, 3)\n",
      "(295, 236, 3)\n",
      "(258, 192, 3)\n",
      "(219, 174, 3)\n",
      "(282, 218, 3)\n",
      "(189, 150, 3)\n",
      "(245, 199, 3)\n",
      "(215, 164, 3)\n",
      "(215, 165, 3)\n",
      "(250, 187, 3)\n",
      "(220, 172, 3)\n",
      "(244, 189, 3)\n",
      "(223, 171, 3)\n",
      "(238, 179, 3)\n",
      "(253, 186, 3)\n",
      "(292, 231, 3)\n",
      "(216, 170, 3)\n",
      "(285, 225, 3)\n",
      "(209, 150, 3)\n",
      "(256, 199, 3)\n",
      "(197, 158, 3)\n",
      "(241, 186, 3)\n",
      "(216, 169, 3)\n",
      "(225, 172, 3)\n",
      "(281, 215, 3)\n",
      "(189, 155, 3)\n",
      "(241, 181, 3)\n",
      "(199, 155, 3)\n",
      "(225, 173, 3)\n",
      "(188, 139, 3)\n",
      "(227, 172, 3)\n",
      "(243, 191, 3)\n",
      "(203, 159, 3)\n",
      "(264, 200, 3)\n",
      "(221, 169, 3)\n",
      "(248, 190, 3)\n",
      "(200, 156, 3)\n",
      "(248, 193, 3)\n",
      "(214, 163, 3)\n",
      "(211, 172, 3)\n",
      "(276, 205, 3)\n",
      "(202, 148, 3)\n",
      "(234, 182, 3)\n",
      "(182, 148, 3)\n",
      "(247, 181, 3)\n",
      "(209, 167, 3)\n",
      "(199, 157, 3)\n",
      "(234, 172, 3)\n",
      "(235, 179, 3)\n",
      "(194, 158, 3)\n",
      "(212, 165, 3)\n",
      "(283, 239, 3)\n",
      "(267, 195, 3)\n",
      "(280, 202, 3)\n",
      "(205, 159, 3)\n",
      "(214, 172, 3)\n",
      "(227, 173, 3)\n",
      "(219, 180, 3)\n",
      "(240, 158, 3)\n",
      "(196, 157, 3)\n",
      "(200, 154, 3)\n",
      "(258, 185, 3)\n",
      "(235, 171, 3)\n",
      "(217, 173, 3)\n",
      "(255, 200, 3)\n",
      "(231, 183, 3)\n",
      "(260, 195, 3)\n",
      "(211, 156, 3)\n",
      "(219, 163, 3)\n",
      "(286, 214, 3)\n",
      "(286, 210, 3)\n",
      "(216, 173, 3)\n",
      "(250, 197, 3)\n",
      "(246, 202, 3)\n",
      "(212, 155, 3)\n",
      "(226, 185, 3)\n",
      "(217, 169, 3)\n",
      "(209, 158, 3)\n",
      "(207, 159, 3)\n",
      "(228, 168, 3)\n",
      "(242, 190, 3)\n",
      "(234, 174, 3)\n",
      "(290, 228, 3)\n",
      "(251, 190, 3)\n",
      "(269, 212, 3)\n",
      "(213, 172, 3)\n",
      "(223, 169, 3)\n",
      "(281, 211, 3)\n",
      "(256, 198, 3)\n",
      "(209, 166, 3)\n",
      "(222, 171, 3)\n",
      "(266, 206, 3)\n",
      "(252, 187, 3)\n",
      "(298, 220, 3)\n",
      "(231, 186, 3)\n",
      "(244, 172, 3)\n",
      "(224, 181, 3)\n",
      "(240, 191, 3)\n",
      "(309, 262, 3)\n",
      "(326, 233, 3)\n",
      "(260, 196, 3)\n",
      "(214, 160, 3)\n",
      "(278, 195, 3)\n",
      "(284, 220, 3)\n",
      "(219, 173, 3)\n",
      "(238, 179, 3)\n",
      "(203, 155, 3)\n",
      "(248, 189, 3)\n",
      "(225, 183, 3)\n",
      "(226, 176, 3)\n",
      "(240, 190, 3)\n",
      "(214, 172, 3)\n",
      "(227, 174, 3)\n",
      "(244, 177, 3)\n",
      "(217, 164, 3)\n",
      "(210, 159, 3)\n",
      "(281, 203, 3)\n",
      "(207, 178, 3)\n",
      "(248, 188, 3)\n",
      "(300, 221, 3)\n",
      "(198, 155, 3)\n",
      "(227, 183, 3)\n",
      "(257, 193, 3)\n",
      "(221, 161, 3)\n",
      "(227, 183, 3)\n",
      "(211, 170, 3)\n",
      "(259, 200, 3)\n",
      "(213, 164, 3)\n",
      "(282, 225, 3)\n",
      "(285, 224, 3)\n",
      "(287, 232, 3)\n",
      "(290, 216, 3)\n",
      "(279, 213, 3)\n",
      "(196, 145, 3)\n",
      "(206, 164, 3)\n",
      "(304, 237, 3)\n",
      "(264, 197, 3)\n",
      "(224, 176, 3)\n",
      "(225, 180, 3)\n",
      "(223, 167, 3)\n",
      "(222, 167, 3)\n",
      "(237, 173, 3)\n",
      "(225, 165, 3)\n",
      "(209, 162, 3)\n",
      "(213, 174, 3)\n",
      "(213, 176, 3)\n",
      "(215, 167, 3)\n",
      "(202, 163, 3)\n",
      "(278, 219, 3)\n",
      "(228, 194, 3)\n",
      "(217, 178, 3)\n",
      "(258, 193, 3)\n",
      "(321, 244, 3)\n",
      "(231, 170, 3)\n",
      "(234, 176, 3)\n",
      "(283, 216, 3)\n",
      "(304, 238, 3)\n",
      "(305, 246, 3)\n",
      "(304, 236, 3)\n",
      "(247, 195, 3)\n",
      "(214, 166, 3)\n",
      "(222, 171, 3)\n",
      "(197, 166, 3)\n",
      "(239, 199, 3)\n",
      "(231, 165, 3)\n",
      "(299, 236, 3)\n",
      "(238, 189, 3)\n",
      "(227, 180, 3)\n",
      "(189, 149, 3)\n",
      "(235, 181, 3)\n",
      "(258, 200, 3)\n",
      "(254, 187, 3)\n",
      "(211, 170, 3)\n",
      "(215, 173, 3)\n",
      "(271, 211, 3)\n",
      "(227, 173, 3)\n",
      "(241, 182, 3)\n",
      "(277, 218, 3)\n",
      "(211, 171, 3)\n",
      "(298, 226, 3)\n",
      "(306, 226, 3)\n",
      "(235, 194, 3)\n",
      "(271, 201, 3)\n",
      "(248, 197, 3)\n",
      "(228, 171, 3)\n",
      "(278, 226, 3)\n",
      "(210, 169, 3)\n",
      "(277, 201, 3)\n",
      "(53, 51, 3)\n",
      "(209, 157, 3)\n",
      "(245, 191, 3)\n",
      "(303, 232, 3)\n",
      "(249, 183, 3)\n",
      "(292, 221, 3)\n",
      "(211, 170, 3)\n",
      "(273, 210, 3)\n",
      "(310, 234, 3)\n",
      "(244, 192, 3)\n",
      "(197, 147, 3)\n",
      "(219, 176, 3)\n",
      "(198, 156, 3)\n",
      "(306, 213, 3)\n",
      "(242, 189, 3)\n",
      "(260, 194, 3)\n",
      "(251, 186, 3)\n",
      "(249, 192, 3)\n",
      "(205, 162, 3)\n",
      "(239, 182, 3)\n",
      "(254, 193, 3)\n",
      "(236, 175, 3)\n",
      "(251, 198, 3)\n",
      "(210, 174, 3)\n",
      "(214, 154, 3)\n",
      "(268, 207, 3)\n",
      "(199, 171, 3)\n",
      "(209, 152, 3)\n",
      "(235, 178, 3)\n",
      "(195, 150, 3)\n",
      "(218, 171, 3)\n",
      "(302, 216, 3)\n",
      "(214, 165, 3)\n",
      "(225, 178, 3)\n",
      "(264, 197, 3)\n",
      "(232, 178, 3)\n",
      "(214, 161, 3)\n",
      "(247, 184, 3)\n",
      "(215, 167, 3)\n",
      "(273, 215, 3)\n",
      "(208, 152, 3)\n",
      "(261, 216, 3)\n",
      "(281, 203, 3)\n",
      "(276, 203, 3)\n",
      "(297, 214, 3)\n",
      "(271, 205, 3)\n",
      "(202, 159, 3)\n",
      "(279, 200, 3)\n",
      "(253, 195, 3)\n",
      "(230, 171, 3)\n",
      "(253, 213, 3)\n",
      "(216, 166, 3)\n",
      "(193, 156, 3)\n",
      "(280, 213, 3)\n",
      "(231, 178, 3)\n",
      "(256, 186, 3)\n",
      "(284, 216, 3)\n",
      "(290, 224, 3)\n",
      "(281, 205, 3)\n",
      "(207, 162, 3)\n",
      "(226, 173, 3)\n",
      "(232, 177, 3)\n",
      "(215, 171, 3)\n",
      "(284, 219, 3)\n",
      "(217, 164, 3)\n",
      "(236, 182, 3)\n",
      "(240, 181, 3)\n",
      "(221, 173, 3)\n",
      "(229, 180, 3)\n",
      "(281, 199, 3)\n",
      "(215, 164, 3)\n",
      "(234, 178, 3)\n",
      "(222, 170, 3)\n",
      "(236, 180, 3)\n",
      "(198, 162, 3)\n",
      "(246, 189, 3)\n",
      "(277, 212, 3)\n",
      "(213, 161, 3)\n",
      "(262, 195, 3)\n",
      "(222, 167, 3)\n",
      "(203, 160, 3)\n",
      "(288, 204, 3)\n",
      "(303, 225, 3)\n",
      "(238, 187, 3)\n",
      "(278, 198, 3)\n",
      "(224, 172, 3)\n",
      "(210, 161, 3)\n",
      "(273, 196, 3)\n",
      "(221, 164, 3)\n",
      "(223, 163, 3)\n",
      "(217, 171, 3)\n",
      "(230, 180, 3)\n",
      "(234, 192, 3)\n",
      "(216, 168, 3)\n",
      "(228, 167, 3)\n",
      "(228, 180, 3)\n",
      "(257, 195, 3)\n",
      "(245, 189, 3)\n",
      "(233, 181, 3)\n",
      "(193, 149, 3)\n",
      "(246, 178, 3)\n",
      "(203, 160, 3)\n",
      "(217, 187, 3)\n",
      "(203, 161, 3)\n",
      "(209, 164, 3)\n",
      "(219, 178, 3)\n",
      "(238, 189, 3)\n",
      "(250, 184, 3)\n",
      "(250, 180, 3)\n",
      "(268, 222, 3)\n",
      "(242, 189, 3)\n",
      "(268, 200, 3)\n",
      "(215, 164, 3)\n",
      "(205, 151, 3)\n",
      "(258, 205, 3)\n",
      "(231, 168, 3)\n",
      "(208, 158, 3)\n",
      "(258, 212, 3)\n",
      "(324, 248, 3)\n",
      "(233, 182, 3)\n",
      "(257, 202, 3)\n",
      "(273, 206, 3)\n",
      "(208, 165, 3)\n",
      "(209, 160, 3)\n",
      "(266, 200, 3)\n",
      "(282, 211, 3)\n",
      "(227, 173, 3)\n",
      "(296, 229, 3)\n",
      "(263, 195, 3)\n",
      "(248, 188, 3)\n",
      "(212, 168, 3)\n",
      "(197, 153, 3)\n",
      "(242, 180, 3)\n",
      "(273, 210, 3)\n",
      "(267, 196, 3)\n",
      "(206, 170, 3)\n",
      "(238, 179, 3)\n",
      "(275, 215, 3)\n",
      "(205, 156, 3)\n",
      "(303, 227, 3)\n",
      "(285, 214, 3)\n",
      "(273, 220, 3)\n",
      "(217, 168, 3)\n",
      "(200, 157, 3)\n",
      "(233, 174, 3)\n",
      "(198, 154, 3)\n",
      "(210, 163, 3)\n",
      "(287, 212, 3)\n",
      "(211, 160, 3)\n",
      "(216, 173, 3)\n",
      "(226, 168, 3)\n",
      "(209, 165, 3)\n",
      "(222, 169, 3)\n",
      "(223, 172, 3)\n",
      "(264, 203, 3)\n",
      "(240, 182, 3)\n",
      "(275, 197, 3)\n",
      "(256, 202, 3)\n",
      "(238, 187, 3)\n",
      "(241, 173, 3)\n",
      "(302, 243, 3)\n",
      "(261, 188, 3)\n",
      "(245, 195, 3)\n",
      "(247, 187, 3)\n",
      "(241, 192, 3)\n",
      "(240, 182, 3)\n",
      "(249, 188, 3)\n",
      "(211, 164, 3)\n",
      "(251, 181, 3)\n",
      "(232, 166, 3)\n",
      "(248, 184, 3)\n",
      "(205, 168, 3)\n",
      "(214, 159, 3)\n",
      "(276, 192, 3)\n",
      "(267, 184, 3)\n",
      "(248, 186, 3)\n",
      "(207, 160, 3)\n",
      "(213, 163, 3)\n",
      "(213, 171, 3)\n",
      "(244, 181, 3)\n",
      "(224, 170, 3)\n",
      "(316, 242, 3)\n",
      "(231, 187, 3)\n",
      "(270, 210, 3)\n",
      "(221, 175, 3)\n",
      "(292, 229, 3)\n",
      "(256, 192, 3)\n",
      "(205, 161, 3)\n",
      "(247, 189, 3)\n",
      "(242, 182, 3)\n",
      "(216, 161, 3)\n",
      "(230, 174, 3)\n",
      "(204, 157, 3)\n",
      "(322, 231, 3)\n",
      "(221, 162, 3)\n",
      "(285, 235, 3)\n",
      "(244, 180, 3)\n",
      "(227, 180, 3)\n",
      "(279, 205, 3)\n",
      "(261, 199, 3)\n",
      "(233, 177, 3)\n",
      "(264, 192, 3)\n",
      "(233, 174, 3)\n",
      "(269, 207, 3)\n",
      "(214, 174, 3)\n",
      "(232, 181, 3)\n",
      "(220, 177, 3)\n",
      "(207, 154, 3)\n",
      "(211, 176, 3)\n",
      "(224, 173, 3)\n",
      "(213, 175, 3)\n",
      "(254, 210, 3)\n",
      "(228, 176, 3)\n",
      "(220, 175, 3)\n",
      "(298, 224, 3)\n",
      "(207, 159, 3)\n",
      "(248, 194, 3)\n",
      "(274, 211, 3)\n",
      "(213, 177, 3)\n",
      "(222, 178, 3)\n",
      "(234, 182, 3)\n",
      "(200, 155, 3)\n",
      "(340, 248, 3)\n",
      "(273, 206, 3)\n",
      "(294, 227, 3)\n",
      "(201, 163, 3)\n",
      "(225, 168, 3)\n",
      "(247, 202, 3)\n",
      "(266, 192, 3)\n",
      "(256, 195, 3)\n",
      "(252, 191, 3)\n",
      "(223, 173, 3)\n",
      "(245, 191, 3)\n",
      "(300, 223, 3)\n",
      "(233, 172, 3)\n",
      "(236, 179, 3)\n",
      "(262, 199, 3)\n",
      "(235, 175, 3)\n",
      "(205, 157, 3)\n",
      "(220, 182, 3)\n",
      "(284, 205, 3)\n",
      "(231, 184, 3)\n",
      "(223, 167, 3)\n",
      "(230, 170, 3)\n",
      "(251, 200, 3)\n",
      "(251, 186, 3)\n",
      "(219, 163, 3)\n",
      "(243, 198, 3)\n",
      "(230, 181, 3)\n",
      "(209, 158, 3)\n",
      "(221, 173, 3)\n",
      "(216, 168, 3)\n",
      "(298, 235, 3)\n",
      "(204, 159, 3)\n",
      "(254, 197, 3)\n",
      "(268, 201, 3)\n",
      "(226, 177, 3)\n",
      "(257, 201, 3)\n",
      "(284, 211, 3)\n",
      "(308, 228, 3)\n",
      "(271, 205, 3)\n",
      "(211, 172, 3)\n",
      "(211, 161, 3)\n",
      "(216, 164, 3)\n",
      "(222, 171, 3)\n",
      "(252, 204, 3)\n",
      "(219, 166, 3)\n",
      "(247, 177, 3)\n",
      "(231, 192, 3)\n",
      "(235, 179, 3)\n",
      "(209, 153, 3)\n",
      "(225, 174, 3)\n",
      "(256, 188, 3)\n",
      "(238, 171, 3)\n",
      "(229, 164, 3)\n",
      "(199, 159, 3)\n",
      "(200, 157, 3)\n",
      "(234, 181, 3)\n",
      "(226, 172, 3)\n",
      "(221, 167, 3)\n",
      "(229, 179, 3)\n",
      "(205, 158, 3)\n",
      "(224, 170, 3)\n",
      "(287, 219, 3)\n",
      "(266, 207, 3)\n",
      "(231, 183, 3)\n",
      "(259, 196, 3)\n",
      "(222, 176, 3)\n",
      "(237, 188, 3)\n",
      "(286, 208, 3)\n",
      "(289, 243, 3)\n",
      "(295, 231, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 173, 3)\n",
      "(241, 180, 3)\n",
      "(203, 156, 3)\n",
      "(290, 231, 3)\n",
      "(225, 181, 3)\n",
      "(253, 199, 3)\n",
      "(236, 174, 3)\n",
      "(264, 214, 3)\n",
      "(230, 175, 3)\n",
      "(199, 171, 3)\n",
      "(242, 178, 3)\n",
      "(243, 192, 3)\n",
      "(274, 203, 3)\n",
      "(236, 175, 3)\n",
      "(227, 184, 3)\n",
      "(214, 163, 3)\n",
      "(303, 221, 3)\n",
      "(262, 199, 3)\n",
      "(226, 178, 3)\n",
      "(262, 203, 3)\n",
      "(270, 181, 3)\n",
      "(248, 181, 3)\n",
      "(246, 181, 3)\n",
      "(220, 165, 3)\n",
      "(288, 225, 3)\n",
      "(227, 173, 3)\n",
      "(206, 156, 3)\n",
      "(203, 157, 3)\n",
      "(259, 202, 3)\n",
      "(228, 198, 3)\n",
      "(287, 245, 3)\n",
      "(205, 168, 3)\n",
      "(229, 185, 3)\n",
      "(240, 189, 3)\n",
      "(238, 186, 3)\n",
      "(251, 194, 3)\n",
      "(275, 214, 3)\n",
      "(262, 205, 3)\n",
      "(204, 149, 3)\n",
      "(253, 197, 3)\n",
      "(263, 199, 3)\n",
      "(226, 173, 3)\n",
      "(201, 158, 3)\n",
      "(275, 194, 3)\n",
      "(244, 195, 3)\n",
      "(218, 169, 3)\n",
      "(221, 160, 3)\n",
      "(268, 208, 3)\n",
      "(228, 172, 3)\n",
      "(204, 168, 3)\n",
      "(178, 149, 3)\n",
      "(256, 190, 3)\n",
      "(242, 180, 3)\n",
      "(311, 220, 3)\n",
      "(219, 173, 3)\n",
      "(200, 152, 3)\n",
      "(226, 176, 3)\n",
      "(225, 174, 3)\n",
      "(261, 187, 3)\n",
      "(270, 201, 3)\n",
      "(250, 185, 3)\n",
      "(290, 206, 3)\n",
      "(203, 161, 3)\n",
      "(244, 188, 3)\n",
      "(240, 193, 3)\n",
      "(185, 138, 3)\n",
      "(224, 168, 3)\n",
      "(200, 147, 3)\n",
      "(238, 179, 3)\n",
      "(254, 194, 3)\n",
      "(275, 196, 3)\n",
      "(218, 163, 3)\n",
      "(252, 194, 3)\n",
      "(199, 149, 3)\n",
      "(226, 176, 3)\n",
      "(206, 159, 3)\n",
      "(236, 188, 3)\n",
      "(289, 232, 3)\n",
      "(232, 168, 3)\n",
      "(204, 162, 3)\n",
      "(232, 165, 3)\n",
      "(227, 176, 3)\n",
      "(236, 179, 3)\n",
      "(226, 169, 3)\n",
      "(238, 182, 3)\n",
      "(250, 184, 3)\n",
      "(262, 199, 3)\n",
      "(260, 189, 3)\n",
      "(309, 241, 3)\n",
      "(237, 190, 3)\n",
      "(239, 178, 3)\n",
      "(216, 173, 3)\n",
      "(245, 196, 3)\n",
      "(207, 164, 3)\n",
      "(294, 210, 3)\n",
      "(285, 215, 3)\n",
      "(273, 214, 3)\n",
      "(243, 193, 3)\n",
      "(203, 165, 3)\n",
      "(282, 223, 3)\n",
      "(228, 182, 3)\n",
      "(296, 215, 3)\n",
      "(216, 171, 3)\n",
      "(209, 157, 3)\n",
      "(217, 177, 3)\n",
      "(232, 177, 3)\n",
      "(278, 213, 3)\n",
      "(255, 202, 3)\n",
      "(271, 196, 3)\n",
      "(313, 248, 3)\n",
      "(253, 188, 3)\n",
      "(245, 187, 3)\n",
      "(213, 164, 3)\n",
      "(262, 202, 3)\n",
      "(242, 184, 3)\n",
      "(216, 162, 3)\n",
      "(301, 231, 3)\n",
      "(202, 153, 3)\n",
      "(246, 184, 3)\n",
      "(225, 175, 3)\n",
      "(180, 144, 3)\n",
      "(227, 179, 3)\n",
      "(232, 184, 3)\n",
      "(260, 196, 3)\n",
      "(233, 184, 3)\n",
      "(258, 194, 3)\n",
      "(205, 163, 3)\n",
      "(216, 170, 3)\n",
      "(237, 176, 3)\n",
      "(242, 176, 3)\n",
      "(230, 173, 3)\n",
      "(290, 220, 3)\n",
      "(269, 194, 3)\n",
      "(217, 176, 3)\n",
      "(276, 196, 3)\n",
      "(211, 163, 3)\n",
      "(245, 189, 3)\n",
      "(262, 202, 3)\n",
      "(250, 187, 3)\n",
      "(216, 161, 3)\n",
      "(223, 174, 3)\n",
      "(255, 195, 3)\n",
      "(271, 205, 3)\n",
      "(222, 180, 3)\n",
      "(237, 187, 3)\n",
      "(188, 154, 3)\n",
      "(236, 165, 3)\n",
      "(203, 161, 3)\n",
      "(223, 171, 3)\n",
      "(252, 190, 3)\n",
      "(216, 166, 3)\n",
      "(271, 225, 3)\n",
      "(274, 206, 3)\n",
      "(236, 179, 3)\n",
      "(257, 192, 3)\n",
      "(319, 236, 3)\n",
      "(250, 193, 3)\n",
      "(221, 177, 3)\n",
      "(261, 207, 3)\n",
      "(228, 179, 3)\n",
      "(222, 168, 3)\n",
      "(238, 189, 3)\n",
      "(272, 218, 3)\n",
      "(248, 194, 3)\n",
      "(228, 178, 3)\n",
      "(270, 211, 3)\n",
      "(241, 196, 3)\n",
      "(254, 199, 3)\n",
      "(251, 184, 3)\n",
      "(239, 178, 3)\n",
      "(275, 220, 3)\n",
      "(230, 176, 3)\n",
      "(253, 190, 3)\n",
      "(238, 174, 3)\n",
      "(212, 163, 3)\n",
      "(214, 155, 3)\n",
      "(273, 203, 3)\n",
      "(252, 183, 3)\n",
      "(241, 183, 3)\n",
      "(193, 149, 3)\n",
      "(211, 169, 3)\n",
      "(232, 176, 3)\n",
      "(238, 184, 3)\n",
      "(207, 161, 3)\n",
      "(274, 201, 3)\n",
      "(278, 207, 3)\n",
      "(233, 188, 3)\n",
      "(260, 189, 3)\n",
      "(316, 247, 3)\n",
      "(231, 171, 3)\n",
      "(233, 190, 3)\n",
      "(273, 210, 3)\n",
      "(194, 152, 3)\n",
      "(209, 167, 3)\n",
      "(228, 175, 3)\n",
      "(250, 187, 3)\n",
      "(214, 164, 3)\n",
      "(235, 178, 3)\n",
      "(225, 177, 3)\n",
      "(292, 223, 3)\n",
      "(234, 175, 3)\n",
      "(225, 173, 3)\n",
      "(301, 235, 3)\n",
      "(241, 190, 3)\n",
      "(277, 200, 3)\n",
      "(211, 160, 3)\n",
      "(305, 259, 3)\n",
      "(250, 189, 3)\n",
      "(214, 162, 3)\n",
      "(215, 165, 3)\n",
      "(218, 158, 3)\n",
      "(286, 213, 3)\n",
      "(228, 166, 3)\n",
      "(261, 209, 3)\n",
      "(280, 207, 3)\n",
      "(240, 170, 3)\n",
      "(218, 168, 3)\n",
      "(233, 172, 3)\n",
      "(236, 169, 3)\n",
      "(278, 207, 3)\n",
      "(268, 208, 3)\n",
      "(261, 196, 3)\n",
      "(251, 204, 3)\n",
      "(323, 240, 3)\n",
      "(268, 190, 3)\n",
      "(269, 209, 3)\n",
      "(216, 164, 3)\n",
      "(224, 180, 3)\n",
      "(228, 175, 3)\n",
      "(216, 164, 3)\n",
      "(289, 218, 3)\n",
      "(263, 201, 3)\n",
      "(230, 178, 3)\n",
      "(231, 170, 3)\n",
      "(223, 170, 3)\n",
      "(216, 167, 3)\n",
      "(231, 172, 3)\n",
      "(206, 158, 3)\n",
      "(304, 238, 3)\n",
      "(260, 196, 3)\n",
      "(241, 187, 3)\n",
      "(303, 230, 3)\n",
      "(246, 186, 3)\n",
      "(268, 205, 3)\n",
      "(315, 230, 3)\n",
      "(215, 166, 3)\n",
      "(243, 176, 3)\n",
      "(313, 228, 3)\n",
      "(221, 169, 3)\n",
      "(238, 182, 3)\n",
      "(204, 162, 3)\n",
      "(289, 216, 3)\n",
      "(273, 201, 3)\n",
      "(197, 156, 3)\n",
      "(190, 148, 3)\n",
      "(206, 157, 3)\n",
      "(215, 168, 3)\n",
      "(229, 179, 3)\n",
      "(221, 168, 3)\n",
      "(226, 176, 3)\n",
      "(219, 170, 3)\n",
      "(267, 214, 3)\n",
      "(242, 187, 3)\n",
      "(221, 171, 3)\n",
      "(226, 182, 3)\n",
      "(291, 221, 3)\n",
      "(249, 198, 3)\n",
      "(224, 174, 3)\n",
      "(218, 179, 3)\n",
      "(209, 155, 3)\n",
      "(251, 188, 3)\n",
      "(223, 168, 3)\n",
      "(231, 175, 3)\n",
      "(235, 174, 3)\n",
      "(310, 234, 3)\n",
      "(245, 194, 3)\n",
      "(217, 169, 3)\n",
      "(250, 188, 3)\n",
      "(248, 197, 3)\n",
      "(207, 165, 3)\n",
      "(211, 167, 3)\n",
      "(243, 178, 3)\n",
      "(210, 160, 3)\n",
      "(236, 183, 3)\n",
      "(306, 246, 3)\n",
      "(273, 216, 3)\n",
      "(214, 167, 3)\n",
      "(230, 172, 3)\n",
      "(254, 190, 3)\n",
      "(240, 189, 3)\n",
      "(250, 189, 3)\n",
      "(264, 199, 3)\n",
      "(235, 182, 3)\n",
      "(224, 173, 3)\n",
      "(221, 175, 3)\n",
      "(215, 167, 3)\n",
      "(222, 168, 3)\n",
      "(219, 168, 3)\n",
      "(264, 201, 3)\n",
      "(202, 162, 3)\n",
      "(233, 185, 3)\n",
      "(224, 160, 3)\n",
      "(200, 155, 3)\n",
      "(259, 195, 3)\n",
      "(312, 234, 3)\n",
      "(225, 177, 3)\n",
      "(217, 172, 3)\n",
      "(258, 191, 3)\n",
      "(233, 189, 3)\n",
      "(203, 157, 3)\n",
      "(200, 148, 3)\n",
      "(190, 143, 3)\n",
      "(229, 172, 3)\n",
      "(220, 168, 3)\n",
      "(232, 186, 3)\n",
      "(253, 193, 3)\n",
      "(293, 215, 3)\n",
      "(247, 196, 3)\n",
      "(238, 184, 3)\n",
      "(224, 181, 3)\n",
      "(207, 162, 3)\n",
      "(211, 170, 3)\n",
      "(217, 164, 3)\n",
      "(202, 150, 3)\n",
      "(248, 194, 3)\n",
      "(209, 152, 3)\n",
      "(220, 163, 3)\n",
      "(213, 168, 3)\n",
      "(218, 173, 3)\n",
      "(194, 149, 3)\n",
      "(231, 174, 3)\n",
      "(332, 254, 3)\n",
      "(249, 198, 3)\n",
      "(222, 182, 3)\n",
      "(246, 191, 3)\n",
      "(245, 182, 3)\n",
      "(212, 168, 3)\n",
      "(249, 196, 3)\n",
      "(232, 184, 3)\n",
      "(216, 172, 3)\n",
      "(239, 172, 3)\n",
      "(236, 181, 3)\n",
      "(223, 186, 3)\n",
      "(207, 155, 3)\n",
      "(217, 163, 3)\n",
      "(239, 188, 3)\n",
      "(276, 201, 3)\n",
      "(237, 172, 3)\n",
      "(235, 183, 3)\n",
      "(246, 187, 3)\n",
      "(230, 171, 3)\n",
      "(237, 169, 3)\n",
      "(234, 188, 3)\n",
      "(240, 176, 3)\n",
      "(238, 199, 3)\n",
      "(249, 195, 3)\n",
      "(211, 166, 3)\n",
      "(248, 190, 3)\n",
      "(216, 171, 3)\n",
      "(231, 169, 3)\n",
      "(230, 176, 3)\n",
      "(232, 180, 3)\n",
      "(280, 204, 3)\n",
      "(294, 221, 3)\n",
      "(239, 188, 3)\n",
      "(198, 154, 3)\n",
      "(220, 170, 3)\n",
      "(215, 164, 3)\n",
      "(242, 175, 3)\n",
      "(243, 194, 3)\n",
      "(238, 174, 3)\n",
      "(292, 230, 3)\n",
      "(257, 197, 3)\n",
      "(219, 171, 3)\n",
      "(240, 182, 3)\n",
      "(222, 176, 3)\n",
      "(238, 189, 3)\n",
      "(236, 172, 3)\n",
      "(237, 178, 3)\n",
      "(231, 165, 3)\n",
      "(276, 210, 3)\n",
      "(204, 154, 3)\n",
      "(235, 184, 3)\n",
      "(198, 157, 3)\n",
      "(239, 173, 3)\n",
      "(233, 173, 3)\n",
      "(257, 180, 3)\n",
      "(243, 172, 3)\n",
      "(213, 160, 3)\n",
      "(292, 223, 3)\n",
      "(219, 162, 3)\n",
      "(191, 148, 3)\n",
      "(171, 135, 3)\n",
      "(234, 169, 3)\n",
      "(311, 241, 3)\n",
      "(205, 163, 3)\n",
      "(205, 171, 3)\n",
      "(275, 212, 3)\n",
      "(234, 180, 3)\n",
      "(225, 182, 3)\n",
      "(217, 166, 3)\n",
      "(264, 201, 3)\n",
      "(251, 199, 3)\n",
      "(255, 191, 3)\n",
      "(262, 201, 3)\n",
      "(224, 170, 3)\n",
      "(268, 206, 3)\n",
      "(275, 211, 3)\n",
      "(293, 233, 3)\n",
      "(266, 191, 3)\n",
      "(210, 167, 3)\n",
      "(209, 162, 3)\n",
      "(228, 176, 3)\n",
      "(242, 189, 3)\n",
      "(222, 170, 3)\n",
      "(241, 175, 3)\n",
      "(241, 182, 3)\n",
      "(210, 164, 3)\n",
      "(232, 171, 3)\n",
      "(285, 207, 3)\n",
      "(202, 167, 3)\n",
      "(245, 183, 3)\n",
      "(262, 193, 3)\n",
      "(221, 167, 3)\n",
      "(235, 194, 3)\n",
      "(226, 178, 3)\n",
      "(216, 165, 3)\n",
      "(222, 176, 3)\n",
      "(224, 167, 3)\n",
      "(204, 162, 3)\n",
      "(247, 188, 3)\n",
      "(198, 154, 3)\n",
      "(279, 206, 3)\n",
      "(198, 152, 3)\n",
      "(245, 180, 3)\n",
      "(201, 154, 3)\n",
      "(217, 175, 3)\n",
      "(201, 154, 3)\n",
      "(240, 192, 3)\n",
      "(226, 169, 3)\n",
      "(228, 182, 3)\n",
      "(196, 148, 3)\n",
      "(243, 188, 3)\n",
      "(234, 189, 3)\n",
      "(211, 152, 3)\n",
      "(273, 209, 3)\n",
      "(218, 166, 3)\n",
      "(258, 190, 3)\n",
      "(290, 226, 3)\n",
      "(193, 170, 3)\n",
      "(234, 179, 3)\n",
      "(214, 162, 3)\n",
      "(263, 200, 3)\n",
      "(236, 190, 3)\n",
      "(261, 194, 3)\n",
      "(249, 189, 3)\n",
      "(192, 154, 3)\n",
      "(221, 177, 3)\n",
      "(279, 213, 3)\n",
      "(258, 206, 3)\n",
      "(244, 185, 3)\n",
      "(228, 172, 3)\n",
      "(220, 177, 3)\n",
      "(220, 164, 3)\n",
      "(235, 173, 3)\n",
      "(262, 202, 3)\n",
      "(241, 191, 3)\n",
      "(251, 195, 3)\n",
      "(227, 178, 3)\n",
      "(221, 176, 3)\n",
      "(278, 213, 3)\n",
      "(215, 164, 3)\n",
      "(216, 169, 3)\n",
      "(250, 192, 3)\n",
      "(272, 196, 3)\n",
      "(283, 211, 3)\n",
      "(233, 172, 3)\n",
      "(235, 189, 3)\n",
      "(304, 215, 3)\n",
      "(247, 193, 3)\n",
      "(223, 180, 3)\n",
      "(288, 216, 3)\n",
      "(222, 169, 3)\n",
      "(226, 169, 3)\n",
      "(243, 198, 3)\n",
      "(221, 175, 3)\n",
      "(212, 163, 3)\n",
      "(199, 155, 3)\n",
      "(244, 183, 3)\n",
      "(286, 228, 3)\n",
      "(226, 165, 3)\n",
      "(200, 154, 3)\n",
      "(223, 163, 3)\n",
      "(208, 159, 3)\n",
      "(252, 202, 3)\n",
      "(239, 196, 3)\n",
      "(221, 166, 3)\n",
      "(269, 201, 3)\n",
      "(219, 178, 3)\n",
      "(227, 173, 3)\n",
      "(194, 160, 3)\n",
      "(233, 172, 3)\n",
      "(239, 195, 3)\n",
      "(254, 186, 3)\n",
      "(240, 185, 3)\n",
      "(239, 182, 3)\n",
      "(314, 241, 3)\n",
      "(262, 203, 3)\n",
      "(216, 163, 3)\n",
      "(233, 194, 3)\n",
      "(257, 200, 3)\n",
      "(253, 200, 3)\n",
      "(217, 175, 3)\n",
      "(230, 180, 3)\n",
      "(221, 168, 3)\n",
      "(283, 208, 3)\n",
      "(210, 157, 3)\n",
      "(230, 178, 3)\n",
      "(245, 190, 3)\n",
      "(239, 177, 3)\n",
      "(250, 199, 3)\n",
      "(240, 195, 3)\n",
      "(241, 183, 3)\n",
      "(244, 189, 3)\n",
      "(225, 179, 3)\n",
      "(233, 184, 3)\n",
      "(190, 146, 3)\n",
      "(229, 161, 3)\n",
      "(271, 209, 3)\n",
      "(242, 175, 3)\n",
      "(226, 172, 3)\n",
      "(298, 234, 3)\n",
      "(256, 206, 3)\n",
      "(260, 190, 3)\n",
      "(257, 193, 3)\n",
      "(264, 199, 3)\n",
      "(219, 173, 3)\n",
      "(211, 157, 3)\n",
      "(248, 195, 3)\n",
      "(245, 176, 3)\n",
      "(284, 226, 3)\n",
      "(211, 162, 3)\n",
      "(242, 186, 3)\n",
      "(285, 213, 3)\n",
      "(234, 172, 3)\n",
      "(309, 228, 3)\n",
      "(241, 193, 3)\n",
      "(219, 175, 3)\n",
      "(216, 164, 3)\n",
      "(248, 195, 3)\n",
      "(223, 182, 3)\n",
      "(241, 186, 3)\n",
      "(287, 211, 3)\n",
      "(246, 192, 3)\n",
      "(238, 182, 3)\n",
      "(206, 170, 3)\n",
      "(247, 193, 3)\n",
      "(330, 252, 3)\n",
      "(278, 207, 3)\n",
      "(219, 178, 3)\n",
      "(186, 152, 3)\n",
      "(267, 219, 3)\n",
      "(240, 179, 3)\n",
      "(293, 211, 3)\n",
      "(213, 157, 3)\n",
      "(229, 173, 3)\n",
      "(200, 156, 3)\n",
      "(250, 193, 3)\n",
      "(227, 175, 3)\n",
      "(250, 212, 3)\n",
      "(245, 189, 3)\n",
      "(228, 166, 3)\n",
      "(217, 164, 3)\n",
      "(247, 188, 3)\n",
      "(233, 173, 3)\n",
      "(293, 223, 3)\n",
      "(232, 176, 3)\n",
      "(260, 193, 3)\n",
      "(220, 163, 3)\n",
      "(288, 219, 3)\n",
      "(205, 152, 3)\n",
      "(219, 164, 3)\n",
      "(248, 187, 3)\n",
      "(297, 234, 3)\n",
      "(266, 199, 3)\n",
      "(248, 190, 3)\n",
      "(220, 155, 3)\n",
      "(208, 164, 3)\n",
      "(221, 165, 3)\n",
      "(217, 181, 3)\n",
      "(256, 183, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 164, 3)\n",
      "(266, 200, 3)\n",
      "(218, 165, 3)\n",
      "(219, 173, 3)\n",
      "(200, 152, 3)\n",
      "(234, 184, 3)\n",
      "(270, 205, 3)\n",
      "(265, 195, 3)\n",
      "(237, 182, 3)\n",
      "(220, 167, 3)\n",
      "(217, 173, 3)\n",
      "(224, 171, 3)\n",
      "(234, 172, 3)\n",
      "(210, 163, 3)\n",
      "(222, 177, 3)\n",
      "(232, 189, 3)\n",
      "(279, 213, 3)\n",
      "(221, 171, 3)\n",
      "(210, 163, 3)\n",
      "(211, 165, 3)\n",
      "(239, 176, 3)\n",
      "(226, 171, 3)\n",
      "(254, 207, 3)\n",
      "(199, 156, 3)\n",
      "(258, 199, 3)\n",
      "(245, 192, 3)\n",
      "(215, 159, 3)\n",
      "(267, 201, 3)\n",
      "(222, 170, 3)\n",
      "(264, 210, 3)\n",
      "(244, 192, 3)\n",
      "(209, 166, 3)\n",
      "(196, 153, 3)\n",
      "(292, 199, 3)\n",
      "(208, 166, 3)\n",
      "(243, 176, 3)\n",
      "(236, 171, 3)\n",
      "(221, 178, 3)\n",
      "(253, 193, 3)\n",
      "(213, 167, 3)\n",
      "(226, 175, 3)\n",
      "(224, 169, 3)\n",
      "(250, 181, 3)\n",
      "(238, 178, 3)\n",
      "(266, 200, 3)\n",
      "(226, 169, 3)\n",
      "(220, 195, 3)\n",
      "(255, 188, 3)\n",
      "(214, 173, 3)\n",
      "(202, 162, 3)\n",
      "(231, 173, 3)\n",
      "(233, 175, 3)\n",
      "(242, 178, 3)\n",
      "(217, 164, 3)\n",
      "(286, 207, 3)\n",
      "(205, 154, 3)\n",
      "(258, 193, 3)\n",
      "(227, 166, 3)\n",
      "(255, 194, 3)\n",
      "(224, 166, 3)\n",
      "(270, 197, 3)\n",
      "(231, 163, 3)\n",
      "(229, 177, 3)\n",
      "(237, 186, 3)\n",
      "(227, 182, 3)\n",
      "(286, 212, 3)\n",
      "(261, 204, 3)\n",
      "(223, 175, 3)\n",
      "(215, 164, 3)\n",
      "(263, 200, 3)\n",
      "(222, 170, 3)\n",
      "(234, 189, 3)\n",
      "(237, 186, 3)\n",
      "(253, 184, 3)\n",
      "(293, 226, 3)\n",
      "(233, 178, 3)\n",
      "(248, 193, 3)\n",
      "(253, 196, 3)\n",
      "(244, 178, 3)\n",
      "(244, 189, 3)\n",
      "(209, 160, 3)\n",
      "(226, 168, 3)\n",
      "(192, 142, 3)\n",
      "(234, 184, 3)\n",
      "(211, 167, 3)\n",
      "(253, 187, 3)\n",
      "(220, 170, 3)\n",
      "(216, 161, 3)\n",
      "(271, 211, 3)\n",
      "(231, 172, 3)\n",
      "(296, 223, 3)\n",
      "(224, 167, 3)\n",
      "(254, 199, 3)\n",
      "(239, 183, 3)\n",
      "(207, 159, 3)\n",
      "(238, 178, 3)\n",
      "(235, 178, 3)\n",
      "(230, 179, 3)\n",
      "(242, 191, 3)\n",
      "(192, 153, 3)\n",
      "(248, 189, 3)\n",
      "(277, 205, 3)\n",
      "(252, 193, 3)\n",
      "(228, 181, 3)\n",
      "(230, 185, 3)\n",
      "(259, 201, 3)\n",
      "(229, 167, 3)\n",
      "(211, 175, 3)\n",
      "(281, 213, 3)\n",
      "(205, 167, 3)\n",
      "(225, 177, 3)\n",
      "(298, 226, 3)\n",
      "(290, 215, 3)\n",
      "(267, 211, 3)\n",
      "(230, 179, 3)\n",
      "(221, 176, 3)\n",
      "(327, 234, 3)\n",
      "(234, 187, 3)\n",
      "(239, 179, 3)\n",
      "(241, 184, 3)\n",
      "(257, 197, 3)\n",
      "(252, 184, 3)\n",
      "(208, 161, 3)\n",
      "(196, 152, 3)\n",
      "(209, 158, 3)\n",
      "(249, 193, 3)\n",
      "(237, 181, 3)\n",
      "(215, 166, 3)\n",
      "(288, 221, 3)\n",
      "(247, 189, 3)\n",
      "(205, 156, 3)\n",
      "(194, 157, 3)\n",
      "(236, 185, 3)\n",
      "(249, 197, 3)\n",
      "(221, 168, 3)\n",
      "(221, 178, 3)\n",
      "(193, 148, 3)\n",
      "(214, 166, 3)\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "target = []\n",
    "for image,score in zip(name_images,scores):\n",
    "    if image.startswith(\"AF\"):\n",
    "        img = detectFace(detector,\"Images\", image)\n",
    "        #print(img.shape)\n",
    "        #if (img.shape[0]==224) and(img.shape[1]==224):\n",
    "        if (img.shape[0] > 30) and (img.shape[1] > 30):\n",
    "            print(img.shape)\n",
    "            img_flip =  cv2.flip(img,1)\n",
    "            all_image = [img,img_flip]\n",
    "            for im in all_image:\n",
    "                data_train.append(im)\n",
    "                target.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):\n",
    "    return K.relu(x,max_value =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(None, Non..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  \n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "/home/minhhv/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_67 (Conv2D)           (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, None, None, 32)    9248      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling_13 ( (None, 21760)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 21760)             87040     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 21760)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                1392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,654,241\n",
      "Trainable params: 2,609,633\n",
      "Non-trainable params: 44,608\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, Activation, MaxPooling2D, Dense\n",
    "from roi_pooling import SpatialPyramidPooling\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# uses theano ordering. Note that we leave the image size as None to allow multiple image sizes\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(None,None,3)))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))          \n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same'))\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(SpatialPyramidPooling([1,2, 4,8]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(64, activation=custom_activation))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dense(32, activation=custom_activation))\n",
    "model.add(Dense(1, activation=custom_activation))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['mse'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(data_train)/255.\n",
    "# y  = np.array(target).reshape((-1,1))\n",
    "#y = to_categorical(y,num_classes=5)\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_train,target,test_size=0.2,random_state=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Sequence):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = np.array(self.x[idx])/255.\n",
    "        batch_y = np.array(self.y[idx]).reshape((-1,1))\n",
    "        return np.expand_dims(batch_x,axis=0),batch_y\n",
    "loader_train = Dataset(x_train, y_train)\n",
    "loader_test = Dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3051/3051 [==============================] - 83s 27ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.80003, saving model to model/regression_roi.h5\n",
      "Epoch 2/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/1000\n",
      "3051/3051 [==============================] - 69s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/1000\n",
      "3051/3051 [==============================] - 69s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/1000\n",
      "3051/3051 [==============================] - 69s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 68/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 69/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 76/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 82/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 86/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 87/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 89/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 93/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 99/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 100/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 103/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 104/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 106/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 107/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 110/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 114/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 117/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 118/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 121/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00121: val_loss did not improve\n",
      "Epoch 122/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00122: val_loss did not improve\n",
      "Epoch 123/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 124/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 125/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00125: val_loss did not improve\n",
      "Epoch 126/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 127/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00127: val_loss did not improve\n",
      "Epoch 128/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00128: val_loss did not improve\n",
      "Epoch 129/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00129: val_loss did not improve\n",
      "Epoch 130/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00130: val_loss did not improve\n",
      "Epoch 131/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00131: val_loss did not improve\n",
      "Epoch 132/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00132: val_loss did not improve\n",
      "Epoch 133/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00133: val_loss did not improve\n",
      "Epoch 134/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00134: val_loss did not improve\n",
      "Epoch 135/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00135: val_loss did not improve\n",
      "Epoch 136/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00136: val_loss did not improve\n",
      "Epoch 137/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00137: val_loss did not improve\n",
      "Epoch 138/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00138: val_loss did not improve\n",
      "Epoch 139/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00139: val_loss did not improve\n",
      "Epoch 140/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00140: val_loss did not improve\n",
      "Epoch 141/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00141: val_loss did not improve\n",
      "Epoch 142/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00142: val_loss did not improve\n",
      "Epoch 143/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00143: val_loss did not improve\n",
      "Epoch 144/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00144: val_loss did not improve\n",
      "Epoch 145/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00145: val_loss did not improve\n",
      "Epoch 146/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00146: val_loss did not improve\n",
      "Epoch 147/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00147: val_loss did not improve\n",
      "Epoch 148/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00148: val_loss did not improve\n",
      "Epoch 149/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00149: val_loss did not improve\n",
      "Epoch 150/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00150: val_loss did not improve\n",
      "Epoch 151/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00151: val_loss did not improve\n",
      "Epoch 152/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00152: val_loss did not improve\n",
      "Epoch 153/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00153: val_loss did not improve\n",
      "Epoch 154/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00154: val_loss did not improve\n",
      "Epoch 155/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00155: val_loss did not improve\n",
      "Epoch 156/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00156: val_loss did not improve\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00157: val_loss did not improve\n",
      "Epoch 158/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00158: val_loss did not improve\n",
      "Epoch 159/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00159: val_loss did not improve\n",
      "Epoch 160/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00160: val_loss did not improve\n",
      "Epoch 161/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00161: val_loss did not improve\n",
      "Epoch 162/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00162: val_loss did not improve\n",
      "Epoch 163/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00163: val_loss did not improve\n",
      "Epoch 164/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00164: val_loss did not improve\n",
      "Epoch 165/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00165: val_loss did not improve\n",
      "Epoch 166/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00166: val_loss did not improve\n",
      "Epoch 167/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00167: val_loss did not improve\n",
      "Epoch 168/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00168: val_loss did not improve\n",
      "Epoch 169/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00169: val_loss did not improve\n",
      "Epoch 170/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00170: val_loss did not improve\n",
      "Epoch 171/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00171: val_loss did not improve\n",
      "Epoch 172/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00172: val_loss did not improve\n",
      "Epoch 173/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00173: val_loss did not improve\n",
      "Epoch 174/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00174: val_loss did not improve\n",
      "Epoch 175/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00175: val_loss did not improve\n",
      "Epoch 176/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00176: val_loss did not improve\n",
      "Epoch 177/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00177: val_loss did not improve\n",
      "Epoch 178/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00178: val_loss did not improve\n",
      "Epoch 179/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00179: val_loss did not improve\n",
      "Epoch 180/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00180: val_loss did not improve\n",
      "Epoch 181/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00181: val_loss did not improve\n",
      "Epoch 182/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00182: val_loss did not improve\n",
      "Epoch 183/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00183: val_loss did not improve\n",
      "Epoch 184/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00184: val_loss did not improve\n",
      "Epoch 185/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00185: val_loss did not improve\n",
      "Epoch 186/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00186: val_loss did not improve\n",
      "Epoch 187/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00187: val_loss did not improve\n",
      "Epoch 188/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00188: val_loss did not improve\n",
      "Epoch 189/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00189: val_loss did not improve\n",
      "Epoch 190/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00190: val_loss did not improve\n",
      "Epoch 191/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00191: val_loss did not improve\n",
      "Epoch 192/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00192: val_loss did not improve\n",
      "Epoch 193/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00193: val_loss did not improve\n",
      "Epoch 194/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00194: val_loss did not improve\n",
      "Epoch 195/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00195: val_loss did not improve\n",
      "Epoch 196/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00196: val_loss did not improve\n",
      "Epoch 197/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00197: val_loss did not improve\n",
      "Epoch 198/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00198: val_loss did not improve\n",
      "Epoch 199/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00199: val_loss did not improve\n",
      "Epoch 200/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00200: val_loss did not improve\n",
      "Epoch 201/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00201: val_loss did not improve\n",
      "Epoch 202/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00202: val_loss did not improve\n",
      "Epoch 203/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00203: val_loss did not improve\n",
      "Epoch 204/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00204: val_loss did not improve\n",
      "Epoch 205/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00205: val_loss did not improve\n",
      "Epoch 206/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00206: val_loss did not improve\n",
      "Epoch 207/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00207: val_loss did not improve\n",
      "Epoch 208/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00208: val_loss did not improve\n",
      "Epoch 209/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00209: val_loss did not improve\n",
      "Epoch 210/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00210: val_loss did not improve\n",
      "Epoch 211/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00211: val_loss did not improve\n",
      "Epoch 212/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00212: val_loss did not improve\n",
      "Epoch 213/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00213: val_loss did not improve\n",
      "Epoch 214/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00214: val_loss did not improve\n",
      "Epoch 215/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00215: val_loss did not improve\n",
      "Epoch 216/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00216: val_loss did not improve\n",
      "Epoch 217/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00217: val_loss did not improve\n",
      "Epoch 218/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00218: val_loss did not improve\n",
      "Epoch 219/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00219: val_loss did not improve\n",
      "Epoch 220/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00220: val_loss did not improve\n",
      "Epoch 221/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00221: val_loss did not improve\n",
      "Epoch 222/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00222: val_loss did not improve\n",
      "Epoch 223/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00223: val_loss did not improve\n",
      "Epoch 224/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00224: val_loss did not improve\n",
      "Epoch 225/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00225: val_loss did not improve\n",
      "Epoch 226/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00226: val_loss did not improve\n",
      "Epoch 227/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00227: val_loss did not improve\n",
      "Epoch 228/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00228: val_loss did not improve\n",
      "Epoch 229/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00229: val_loss did not improve\n",
      "Epoch 230/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00230: val_loss did not improve\n",
      "Epoch 231/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00231: val_loss did not improve\n",
      "Epoch 232/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00232: val_loss did not improve\n",
      "Epoch 233/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00233: val_loss did not improve\n",
      "Epoch 234/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00234: val_loss did not improve\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00235: val_loss did not improve\n",
      "Epoch 236/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00236: val_loss did not improve\n",
      "Epoch 237/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00237: val_loss did not improve\n",
      "Epoch 238/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00238: val_loss did not improve\n",
      "Epoch 239/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00239: val_loss did not improve\n",
      "Epoch 240/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00240: val_loss did not improve\n",
      "Epoch 241/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00241: val_loss did not improve\n",
      "Epoch 242/1000\n",
      "3051/3051 [==============================] - 69s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00242: val_loss did not improve\n",
      "Epoch 243/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00243: val_loss did not improve\n",
      "Epoch 244/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00244: val_loss did not improve\n",
      "Epoch 245/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00245: val_loss did not improve\n",
      "Epoch 246/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00246: val_loss did not improve\n",
      "Epoch 247/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00247: val_loss did not improve\n",
      "Epoch 248/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00248: val_loss did not improve\n",
      "Epoch 249/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00249: val_loss did not improve\n",
      "Epoch 250/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00250: val_loss did not improve\n",
      "Epoch 251/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00251: val_loss did not improve\n",
      "Epoch 252/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00252: val_loss did not improve\n",
      "Epoch 253/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00253: val_loss did not improve\n",
      "Epoch 254/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00254: val_loss did not improve\n",
      "Epoch 255/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00255: val_loss did not improve\n",
      "Epoch 256/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00256: val_loss did not improve\n",
      "Epoch 257/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00257: val_loss did not improve\n",
      "Epoch 258/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00258: val_loss did not improve\n",
      "Epoch 259/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00259: val_loss did not improve\n",
      "Epoch 260/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00260: val_loss did not improve\n",
      "Epoch 261/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00261: val_loss did not improve\n",
      "Epoch 262/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00262: val_loss did not improve\n",
      "Epoch 263/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00263: val_loss did not improve\n",
      "Epoch 264/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00264: val_loss did not improve\n",
      "Epoch 265/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00265: val_loss did not improve\n",
      "Epoch 266/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00266: val_loss did not improve\n",
      "Epoch 267/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00267: val_loss did not improve\n",
      "Epoch 268/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00268: val_loss did not improve\n",
      "Epoch 269/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00269: val_loss did not improve\n",
      "Epoch 270/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00270: val_loss did not improve\n",
      "Epoch 271/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00271: val_loss did not improve\n",
      "Epoch 272/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00272: val_loss did not improve\n",
      "Epoch 273/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00273: val_loss did not improve\n",
      "Epoch 274/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00274: val_loss did not improve\n",
      "Epoch 275/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00275: val_loss did not improve\n",
      "Epoch 276/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00276: val_loss did not improve\n",
      "Epoch 277/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00277: val_loss did not improve\n",
      "Epoch 278/1000\n",
      "3051/3051 [==============================] - 75s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00278: val_loss did not improve\n",
      "Epoch 279/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00279: val_loss did not improve\n",
      "Epoch 280/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00280: val_loss did not improve\n",
      "Epoch 281/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00281: val_loss did not improve\n",
      "Epoch 282/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00282: val_loss did not improve\n",
      "Epoch 283/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00283: val_loss did not improve\n",
      "Epoch 284/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00284: val_loss did not improve\n",
      "Epoch 285/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00285: val_loss did not improve\n",
      "Epoch 286/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00286: val_loss did not improve\n",
      "Epoch 287/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00287: val_loss did not improve\n",
      "Epoch 288/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00288: val_loss did not improve\n",
      "Epoch 289/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00289: val_loss did not improve\n",
      "Epoch 290/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00290: val_loss did not improve\n",
      "Epoch 291/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00291: val_loss did not improve\n",
      "Epoch 292/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00292: val_loss did not improve\n",
      "Epoch 293/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00293: val_loss did not improve\n",
      "Epoch 294/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00294: val_loss did not improve\n",
      "Epoch 295/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00295: val_loss did not improve\n",
      "Epoch 296/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00296: val_loss did not improve\n",
      "Epoch 297/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00297: val_loss did not improve\n",
      "Epoch 298/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00298: val_loss did not improve\n",
      "Epoch 299/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00299: val_loss did not improve\n",
      "Epoch 300/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00300: val_loss did not improve\n",
      "Epoch 301/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00301: val_loss did not improve\n",
      "Epoch 302/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00302: val_loss did not improve\n",
      "Epoch 303/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00303: val_loss did not improve\n",
      "Epoch 304/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00304: val_loss did not improve\n",
      "Epoch 305/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00305: val_loss did not improve\n",
      "Epoch 306/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00306: val_loss did not improve\n",
      "Epoch 307/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00307: val_loss did not improve\n",
      "Epoch 308/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00308: val_loss did not improve\n",
      "Epoch 309/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00309: val_loss did not improve\n",
      "Epoch 310/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00310: val_loss did not improve\n",
      "Epoch 311/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00311: val_loss did not improve\n",
      "Epoch 312/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00312: val_loss did not improve\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00313: val_loss did not improve\n",
      "Epoch 314/1000\n",
      "3051/3051 [==============================] - 69s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00314: val_loss did not improve\n",
      "Epoch 315/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00315: val_loss did not improve\n",
      "Epoch 316/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00316: val_loss did not improve\n",
      "Epoch 317/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00317: val_loss did not improve\n",
      "Epoch 318/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00318: val_loss did not improve\n",
      "Epoch 319/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00319: val_loss did not improve\n",
      "Epoch 320/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00320: val_loss did not improve\n",
      "Epoch 321/1000\n",
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00321: val_loss did not improve\n",
      "Epoch 322/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00322: val_loss did not improve\n",
      "Epoch 323/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00323: val_loss did not improve\n",
      "Epoch 324/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00324: val_loss did not improve\n",
      "Epoch 325/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00325: val_loss did not improve\n",
      "Epoch 326/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00326: val_loss did not improve\n",
      "Epoch 327/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00327: val_loss did not improve\n",
      "Epoch 328/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00328: val_loss did not improve\n",
      "Epoch 329/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00329: val_loss did not improve\n",
      "Epoch 330/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00330: val_loss did not improve\n",
      "Epoch 331/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00331: val_loss did not improve\n",
      "Epoch 332/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00332: val_loss did not improve\n",
      "Epoch 333/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00333: val_loss did not improve\n",
      "Epoch 334/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00334: val_loss did not improve\n",
      "Epoch 335/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00335: val_loss did not improve\n",
      "Epoch 336/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00336: val_loss did not improve\n",
      "Epoch 337/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00337: val_loss did not improve\n",
      "Epoch 338/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00338: val_loss did not improve\n",
      "Epoch 339/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00339: val_loss did not improve\n",
      "Epoch 340/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00340: val_loss did not improve\n",
      "Epoch 341/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00341: val_loss did not improve\n",
      "Epoch 342/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00342: val_loss did not improve\n",
      "Epoch 343/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00343: val_loss did not improve\n",
      "Epoch 344/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00344: val_loss did not improve\n",
      "Epoch 345/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00345: val_loss did not improve\n",
      "Epoch 346/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00346: val_loss did not improve\n",
      "Epoch 347/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00347: val_loss did not improve\n",
      "Epoch 348/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00348: val_loss did not improve\n",
      "Epoch 349/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00349: val_loss did not improve\n",
      "Epoch 350/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00350: val_loss did not improve\n",
      "Epoch 351/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00351: val_loss did not improve\n",
      "Epoch 352/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00352: val_loss did not improve\n",
      "Epoch 353/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00353: val_loss did not improve\n",
      "Epoch 354/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00354: val_loss did not improve\n",
      "Epoch 355/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00355: val_loss did not improve\n",
      "Epoch 356/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00356: val_loss did not improve\n",
      "Epoch 357/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00357: val_loss did not improve\n",
      "Epoch 358/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00358: val_loss did not improve\n",
      "Epoch 359/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00359: val_loss did not improve\n",
      "Epoch 360/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00360: val_loss did not improve\n",
      "Epoch 361/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00361: val_loss did not improve\n",
      "Epoch 362/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00362: val_loss did not improve\n",
      "Epoch 363/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00363: val_loss did not improve\n",
      "Epoch 364/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00364: val_loss did not improve\n",
      "Epoch 365/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00365: val_loss did not improve\n",
      "Epoch 366/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00366: val_loss did not improve\n",
      "Epoch 367/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00367: val_loss did not improve\n",
      "Epoch 368/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00368: val_loss did not improve\n",
      "Epoch 369/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00369: val_loss did not improve\n",
      "Epoch 370/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00370: val_loss did not improve\n",
      "Epoch 371/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00371: val_loss did not improve\n",
      "Epoch 372/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00372: val_loss did not improve\n",
      "Epoch 373/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00373: val_loss did not improve\n",
      "Epoch 374/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00374: val_loss did not improve\n",
      "Epoch 375/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00375: val_loss did not improve\n",
      "Epoch 376/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00376: val_loss did not improve\n",
      "Epoch 377/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00377: val_loss did not improve\n",
      "Epoch 378/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00378: val_loss did not improve\n",
      "Epoch 379/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00379: val_loss did not improve\n",
      "Epoch 380/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00380: val_loss did not improve\n",
      "Epoch 381/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00381: val_loss did not improve\n",
      "Epoch 382/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00382: val_loss did not improve\n",
      "Epoch 383/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00383: val_loss did not improve\n",
      "Epoch 384/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00384: val_loss did not improve\n",
      "Epoch 385/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00385: val_loss did not improve\n",
      "Epoch 386/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00386: val_loss did not improve\n",
      "Epoch 387/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00387: val_loss did not improve\n",
      "Epoch 388/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00388: val_loss did not improve\n",
      "Epoch 389/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00389: val_loss did not improve\n",
      "Epoch 390/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00390: val_loss did not improve\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00391: val_loss did not improve\n",
      "Epoch 392/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00392: val_loss did not improve\n",
      "Epoch 393/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00393: val_loss did not improve\n",
      "Epoch 394/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00394: val_loss did not improve\n",
      "Epoch 395/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00395: val_loss did not improve\n",
      "Epoch 396/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00396: val_loss did not improve\n",
      "Epoch 397/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00397: val_loss did not improve\n",
      "Epoch 398/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00398: val_loss did not improve\n",
      "Epoch 399/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00399: val_loss did not improve\n",
      "Epoch 400/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00400: val_loss did not improve\n",
      "Epoch 401/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00401: val_loss did not improve\n",
      "Epoch 402/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00402: val_loss did not improve\n",
      "Epoch 403/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00403: val_loss did not improve\n",
      "Epoch 404/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00404: val_loss did not improve\n",
      "Epoch 405/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00405: val_loss did not improve\n",
      "Epoch 406/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00406: val_loss did not improve\n",
      "Epoch 407/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00407: val_loss did not improve\n",
      "Epoch 408/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00408: val_loss did not improve\n",
      "Epoch 409/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00409: val_loss did not improve\n",
      "Epoch 410/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00410: val_loss did not improve\n",
      "Epoch 411/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00411: val_loss did not improve\n",
      "Epoch 412/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00412: val_loss did not improve\n",
      "Epoch 413/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00413: val_loss did not improve\n",
      "Epoch 414/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00414: val_loss did not improve\n",
      "Epoch 415/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00415: val_loss did not improve\n",
      "Epoch 416/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00416: val_loss did not improve\n",
      "Epoch 417/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00417: val_loss did not improve\n",
      "Epoch 418/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00418: val_loss did not improve\n",
      "Epoch 419/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00419: val_loss did not improve\n",
      "Epoch 420/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00420: val_loss did not improve\n",
      "Epoch 421/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00421: val_loss did not improve\n",
      "Epoch 422/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00422: val_loss did not improve\n",
      "Epoch 423/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00423: val_loss did not improve\n",
      "Epoch 424/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00424: val_loss did not improve\n",
      "Epoch 425/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00425: val_loss did not improve\n",
      "Epoch 426/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00426: val_loss did not improve\n",
      "Epoch 427/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00427: val_loss did not improve\n",
      "Epoch 428/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00428: val_loss did not improve\n",
      "Epoch 429/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00429: val_loss did not improve\n",
      "Epoch 430/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00430: val_loss did not improve\n",
      "Epoch 431/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00431: val_loss did not improve\n",
      "Epoch 432/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00432: val_loss did not improve\n",
      "Epoch 433/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00433: val_loss did not improve\n",
      "Epoch 434/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00434: val_loss did not improve\n",
      "Epoch 435/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00435: val_loss did not improve\n",
      "Epoch 436/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00436: val_loss did not improve\n",
      "Epoch 437/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00437: val_loss did not improve\n",
      "Epoch 438/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00438: val_loss did not improve\n",
      "Epoch 439/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00439: val_loss did not improve\n",
      "Epoch 440/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00440: val_loss did not improve\n",
      "Epoch 441/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00441: val_loss did not improve\n",
      "Epoch 442/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00442: val_loss did not improve\n",
      "Epoch 443/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00443: val_loss did not improve\n",
      "Epoch 444/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00444: val_loss did not improve\n",
      "Epoch 445/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00445: val_loss did not improve\n",
      "Epoch 446/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00446: val_loss did not improve\n",
      "Epoch 447/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00447: val_loss did not improve\n",
      "Epoch 448/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00448: val_loss did not improve\n",
      "Epoch 449/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00449: val_loss did not improve\n",
      "Epoch 450/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00450: val_loss did not improve\n",
      "Epoch 451/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00451: val_loss did not improve\n",
      "Epoch 452/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00452: val_loss did not improve\n",
      "Epoch 453/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00453: val_loss did not improve\n",
      "Epoch 454/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00454: val_loss did not improve\n",
      "Epoch 455/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00455: val_loss did not improve\n",
      "Epoch 456/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00456: val_loss did not improve\n",
      "Epoch 457/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00457: val_loss did not improve\n",
      "Epoch 458/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00458: val_loss did not improve\n",
      "Epoch 459/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00459: val_loss did not improve\n",
      "Epoch 460/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00460: val_loss did not improve\n",
      "Epoch 461/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00461: val_loss did not improve\n",
      "Epoch 462/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00462: val_loss did not improve\n",
      "Epoch 463/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00463: val_loss did not improve\n",
      "Epoch 464/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00464: val_loss did not improve\n",
      "Epoch 465/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00465: val_loss did not improve\n",
      "Epoch 466/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00466: val_loss did not improve\n",
      "Epoch 467/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00467: val_loss did not improve\n",
      "Epoch 468/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00468: val_loss did not improve\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 68s 22ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00469: val_loss did not improve\n",
      "Epoch 470/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00470: val_loss did not improve\n",
      "Epoch 471/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00471: val_loss did not improve\n",
      "Epoch 472/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00472: val_loss did not improve\n",
      "Epoch 473/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00473: val_loss did not improve\n",
      "Epoch 474/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00474: val_loss did not improve\n",
      "Epoch 475/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00475: val_loss did not improve\n",
      "Epoch 476/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00476: val_loss did not improve\n",
      "Epoch 477/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00477: val_loss did not improve\n",
      "Epoch 478/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00478: val_loss did not improve\n",
      "Epoch 479/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00479: val_loss did not improve\n",
      "Epoch 480/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00480: val_loss did not improve\n",
      "Epoch 481/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00481: val_loss did not improve\n",
      "Epoch 482/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00482: val_loss did not improve\n",
      "Epoch 483/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00483: val_loss did not improve\n",
      "Epoch 484/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00484: val_loss did not improve\n",
      "Epoch 485/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00485: val_loss did not improve\n",
      "Epoch 486/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00486: val_loss did not improve\n",
      "Epoch 487/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00487: val_loss did not improve\n",
      "Epoch 488/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00488: val_loss did not improve\n",
      "Epoch 489/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00489: val_loss did not improve\n",
      "Epoch 490/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00490: val_loss did not improve\n",
      "Epoch 491/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00491: val_loss did not improve\n",
      "Epoch 492/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00492: val_loss did not improve\n",
      "Epoch 493/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00493: val_loss did not improve\n",
      "Epoch 494/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00494: val_loss did not improve\n",
      "Epoch 495/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00495: val_loss did not improve\n",
      "Epoch 496/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00496: val_loss did not improve\n",
      "Epoch 497/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00497: val_loss did not improve\n",
      "Epoch 498/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00498: val_loss did not improve\n",
      "Epoch 499/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00499: val_loss did not improve\n",
      "Epoch 500/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00500: val_loss did not improve\n",
      "Epoch 501/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00501: val_loss did not improve\n",
      "Epoch 502/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00502: val_loss did not improve\n",
      "Epoch 503/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00503: val_loss did not improve\n",
      "Epoch 504/1000\n",
      "3051/3051 [==============================] - 75s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00504: val_loss did not improve\n",
      "Epoch 505/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00505: val_loss did not improve\n",
      "Epoch 506/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00506: val_loss did not improve\n",
      "Epoch 507/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00507: val_loss did not improve\n",
      "Epoch 508/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00508: val_loss did not improve\n",
      "Epoch 509/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00509: val_loss did not improve\n",
      "Epoch 510/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00510: val_loss did not improve\n",
      "Epoch 511/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00511: val_loss did not improve\n",
      "Epoch 512/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00512: val_loss did not improve\n",
      "Epoch 513/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00513: val_loss did not improve\n",
      "Epoch 514/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00514: val_loss did not improve\n",
      "Epoch 515/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00515: val_loss did not improve\n",
      "Epoch 516/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00516: val_loss did not improve\n",
      "Epoch 517/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00517: val_loss did not improve\n",
      "Epoch 518/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00518: val_loss did not improve\n",
      "Epoch 519/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00519: val_loss did not improve\n",
      "Epoch 520/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00520: val_loss did not improve\n",
      "Epoch 521/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00521: val_loss did not improve\n",
      "Epoch 522/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00522: val_loss did not improve\n",
      "Epoch 523/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00523: val_loss did not improve\n",
      "Epoch 524/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00524: val_loss did not improve\n",
      "Epoch 525/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00525: val_loss did not improve\n",
      "Epoch 526/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00526: val_loss did not improve\n",
      "Epoch 527/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00527: val_loss did not improve\n",
      "Epoch 528/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00528: val_loss did not improve\n",
      "Epoch 529/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00529: val_loss did not improve\n",
      "Epoch 530/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00530: val_loss did not improve\n",
      "Epoch 531/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00531: val_loss did not improve\n",
      "Epoch 532/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00532: val_loss did not improve\n",
      "Epoch 533/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00533: val_loss did not improve\n",
      "Epoch 534/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00534: val_loss did not improve\n",
      "Epoch 535/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00535: val_loss did not improve\n",
      "Epoch 536/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00536: val_loss did not improve\n",
      "Epoch 537/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00537: val_loss did not improve\n",
      "Epoch 538/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00538: val_loss did not improve\n",
      "Epoch 539/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00539: val_loss did not improve\n",
      "Epoch 540/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00540: val_loss did not improve\n",
      "Epoch 541/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00541: val_loss did not improve\n",
      "Epoch 542/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00542: val_loss did not improve\n",
      "Epoch 543/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00543: val_loss did not improve\n",
      "Epoch 544/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00544: val_loss did not improve\n",
      "Epoch 545/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00545: val_loss did not improve\n",
      "Epoch 546/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00546: val_loss did not improve\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00547: val_loss did not improve\n",
      "Epoch 548/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00548: val_loss did not improve\n",
      "Epoch 549/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00549: val_loss did not improve\n",
      "Epoch 550/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00550: val_loss did not improve\n",
      "Epoch 551/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00551: val_loss did not improve\n",
      "Epoch 552/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00552: val_loss did not improve\n",
      "Epoch 553/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00553: val_loss did not improve\n",
      "Epoch 554/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00554: val_loss did not improve\n",
      "Epoch 555/1000\n",
      "3051/3051 [==============================] - 84s 28ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00555: val_loss did not improve\n",
      "Epoch 556/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00556: val_loss did not improve\n",
      "Epoch 557/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00557: val_loss did not improve\n",
      "Epoch 558/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00558: val_loss did not improve\n",
      "Epoch 559/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00559: val_loss did not improve\n",
      "Epoch 560/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00560: val_loss did not improve\n",
      "Epoch 561/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00561: val_loss did not improve\n",
      "Epoch 562/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00562: val_loss did not improve\n",
      "Epoch 563/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00563: val_loss did not improve\n",
      "Epoch 564/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00564: val_loss did not improve\n",
      "Epoch 565/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00565: val_loss did not improve\n",
      "Epoch 566/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00566: val_loss did not improve\n",
      "Epoch 567/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00567: val_loss did not improve\n",
      "Epoch 568/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00568: val_loss did not improve\n",
      "Epoch 569/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00569: val_loss did not improve\n",
      "Epoch 570/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00570: val_loss did not improve\n",
      "Epoch 571/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00571: val_loss did not improve\n",
      "Epoch 572/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00572: val_loss did not improve\n",
      "Epoch 573/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00573: val_loss did not improve\n",
      "Epoch 574/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00574: val_loss did not improve\n",
      "Epoch 575/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00575: val_loss did not improve\n",
      "Epoch 576/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00576: val_loss did not improve\n",
      "Epoch 577/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00577: val_loss did not improve\n",
      "Epoch 578/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00578: val_loss did not improve\n",
      "Epoch 579/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00579: val_loss did not improve\n",
      "Epoch 580/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00580: val_loss did not improve\n",
      "Epoch 581/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00581: val_loss did not improve\n",
      "Epoch 582/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00582: val_loss did not improve\n",
      "Epoch 583/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00583: val_loss did not improve\n",
      "Epoch 584/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00584: val_loss did not improve\n",
      "Epoch 585/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00585: val_loss did not improve\n",
      "Epoch 586/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00586: val_loss did not improve\n",
      "Epoch 587/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00587: val_loss did not improve\n",
      "Epoch 588/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00588: val_loss did not improve\n",
      "Epoch 589/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00589: val_loss did not improve\n",
      "Epoch 590/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00590: val_loss did not improve\n",
      "Epoch 591/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00591: val_loss did not improve\n",
      "Epoch 592/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00592: val_loss did not improve\n",
      "Epoch 593/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00593: val_loss did not improve\n",
      "Epoch 594/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00594: val_loss did not improve\n",
      "Epoch 595/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00595: val_loss did not improve\n",
      "Epoch 596/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00596: val_loss did not improve\n",
      "Epoch 597/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00597: val_loss did not improve\n",
      "Epoch 598/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00598: val_loss did not improve\n",
      "Epoch 599/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00599: val_loss did not improve\n",
      "Epoch 600/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00600: val_loss did not improve\n",
      "Epoch 601/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00601: val_loss did not improve\n",
      "Epoch 602/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00602: val_loss did not improve\n",
      "Epoch 603/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00603: val_loss did not improve\n",
      "Epoch 604/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00604: val_loss did not improve\n",
      "Epoch 605/1000\n",
      "3051/3051 [==============================] - 74s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00605: val_loss did not improve\n",
      "Epoch 606/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00606: val_loss did not improve\n",
      "Epoch 607/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00607: val_loss did not improve\n",
      "Epoch 608/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00608: val_loss did not improve\n",
      "Epoch 609/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00609: val_loss did not improve\n",
      "Epoch 610/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00610: val_loss did not improve\n",
      "Epoch 611/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00611: val_loss did not improve\n",
      "Epoch 612/1000\n",
      "3051/3051 [==============================] - 76s 25ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00612: val_loss did not improve\n",
      "Epoch 613/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00613: val_loss did not improve\n",
      "Epoch 614/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00614: val_loss did not improve\n",
      "Epoch 615/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00615: val_loss did not improve\n",
      "Epoch 616/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00616: val_loss did not improve\n",
      "Epoch 617/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00617: val_loss did not improve\n",
      "Epoch 618/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00618: val_loss did not improve\n",
      "Epoch 619/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00619: val_loss did not improve\n",
      "Epoch 620/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00620: val_loss did not improve\n",
      "Epoch 621/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00621: val_loss did not improve\n",
      "Epoch 622/1000\n",
      "3051/3051 [==============================] - 69s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00622: val_loss did not improve\n",
      "Epoch 623/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00623: val_loss did not improve\n",
      "Epoch 624/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00624: val_loss did not improve\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00625: val_loss did not improve\n",
      "Epoch 626/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00626: val_loss did not improve\n",
      "Epoch 627/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00627: val_loss did not improve\n",
      "Epoch 628/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00628: val_loss did not improve\n",
      "Epoch 629/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00629: val_loss did not improve\n",
      "Epoch 630/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00630: val_loss did not improve\n",
      "Epoch 631/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00631: val_loss did not improve\n",
      "Epoch 632/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00632: val_loss did not improve\n",
      "Epoch 633/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00633: val_loss did not improve\n",
      "Epoch 634/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00634: val_loss did not improve\n",
      "Epoch 635/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00635: val_loss did not improve\n",
      "Epoch 636/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00636: val_loss did not improve\n",
      "Epoch 637/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00637: val_loss did not improve\n",
      "Epoch 638/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00638: val_loss did not improve\n",
      "Epoch 639/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00639: val_loss did not improve\n",
      "Epoch 640/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00640: val_loss did not improve\n",
      "Epoch 641/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00641: val_loss did not improve\n",
      "Epoch 642/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00642: val_loss did not improve\n",
      "Epoch 643/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00643: val_loss did not improve\n",
      "Epoch 644/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00644: val_loss did not improve\n",
      "Epoch 645/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00645: val_loss did not improve\n",
      "Epoch 646/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00646: val_loss did not improve\n",
      "Epoch 647/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00647: val_loss did not improve\n",
      "Epoch 648/1000\n",
      "3051/3051 [==============================] - 70s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00648: val_loss did not improve\n",
      "Epoch 649/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00649: val_loss did not improve\n",
      "Epoch 650/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00650: val_loss did not improve\n",
      "Epoch 651/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00651: val_loss did not improve\n",
      "Epoch 652/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00652: val_loss did not improve\n",
      "Epoch 653/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00653: val_loss did not improve\n",
      "Epoch 654/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00654: val_loss did not improve\n",
      "Epoch 655/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00655: val_loss did not improve\n",
      "Epoch 656/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00656: val_loss did not improve\n",
      "Epoch 657/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00657: val_loss did not improve\n",
      "Epoch 658/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00658: val_loss did not improve\n",
      "Epoch 659/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00659: val_loss did not improve\n",
      "Epoch 660/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00660: val_loss did not improve\n",
      "Epoch 661/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00661: val_loss did not improve\n",
      "Epoch 662/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00662: val_loss did not improve\n",
      "Epoch 663/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00663: val_loss did not improve\n",
      "Epoch 664/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00664: val_loss did not improve\n",
      "Epoch 665/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00665: val_loss did not improve\n",
      "Epoch 666/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00666: val_loss did not improve\n",
      "Epoch 667/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00667: val_loss did not improve\n",
      "Epoch 668/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00668: val_loss did not improve\n",
      "Epoch 669/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00669: val_loss did not improve\n",
      "Epoch 670/1000\n",
      "3051/3051 [==============================] - 71s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00670: val_loss did not improve\n",
      "Epoch 671/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00671: val_loss did not improve\n",
      "Epoch 672/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00672: val_loss did not improve\n",
      "Epoch 673/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00673: val_loss did not improve\n",
      "Epoch 674/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00674: val_loss did not improve\n",
      "Epoch 675/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00675: val_loss did not improve\n",
      "Epoch 676/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00676: val_loss did not improve\n",
      "Epoch 677/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00677: val_loss did not improve\n",
      "Epoch 678/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00678: val_loss did not improve\n",
      "Epoch 679/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00679: val_loss did not improve\n",
      "Epoch 680/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00680: val_loss did not improve\n",
      "Epoch 681/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00681: val_loss did not improve\n",
      "Epoch 682/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00682: val_loss did not improve\n",
      "Epoch 683/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00683: val_loss did not improve\n",
      "Epoch 684/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00684: val_loss did not improve\n",
      "Epoch 685/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00685: val_loss did not improve\n",
      "Epoch 686/1000\n",
      "3051/3051 [==============================] - 73s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00686: val_loss did not improve\n",
      "Epoch 687/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00687: val_loss did not improve\n",
      "Epoch 688/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00688: val_loss did not improve\n",
      "Epoch 689/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00689: val_loss did not improve\n",
      "Epoch 690/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00690: val_loss did not improve\n",
      "Epoch 691/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00691: val_loss did not improve\n",
      "Epoch 692/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00692: val_loss did not improve\n",
      "Epoch 693/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00693: val_loss did not improve\n",
      "Epoch 694/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00694: val_loss did not improve\n",
      "Epoch 695/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00695: val_loss did not improve\n",
      "Epoch 696/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00696: val_loss did not improve\n",
      "Epoch 697/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00697: val_loss did not improve\n",
      "Epoch 698/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00698: val_loss did not improve\n",
      "Epoch 699/1000\n",
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00699: val_loss did not improve\n",
      "Epoch 700/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00700: val_loss did not improve\n",
      "Epoch 701/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00701: val_loss did not improve\n",
      "Epoch 702/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00702: val_loss did not improve\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3051/3051 [==============================] - 72s 23ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00703: val_loss did not improve\n",
      "Epoch 704/1000\n",
      "3051/3051 [==============================] - 72s 24ms/step - loss: 9.7454 - mean_squared_error: 9.7454 - val_loss: 9.8000 - val_mean_squared_error: 9.8000\n",
      "\n",
      "Epoch 00704: val_loss did not improve\n",
      "Epoch 705/1000\n",
      "2228/3051 [====================>.........] - ETA: 17s - loss: 9.7195 - mean_squared_error: 9.7195"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-38d6b6b5166f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model/regression_roi.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mckp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mckp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='auto')\n",
    "weight_path = 'model/regression_roi.h5'\n",
    "ckp = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "history = model.fit_generator(loader_train,epochs=1000,validation_data=loader_test,callbacks=[ckp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
